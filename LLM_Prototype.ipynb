{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63226100-4da6-409f-a822-ff743e3240ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e9d948a-f00e-4e74-9ade-98ff7b74f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b104f43-b241-415d-a70f-131bd08ab27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1ee42e-4f97-49d3-832f-886707559da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b99fe45-218e-4ded-8c16-2c4acef76bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.generative_models import GenerativeModel, Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf77dea-7464-414d-b406-fed7599a5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=project_id,\n",
    "    location=local\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9148dc6d-055a-4b3e-80cb-951b63bfef84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /opt/anaconda3/lib/python3.12/site-packages (1.106.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (6.31.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (25.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (3.35.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (1.14.2)\n",
      "Requirement already satisfied: shapely<3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.1.1)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (1.27.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (2.5.3)\n",
      "Requirement already satisfied: typing_extensions in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (4.11.0)\n",
      "Requirement already satisfied: docstring_parser<1 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-aiplatform) (0.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.32.2)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.74.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-cloud-storage<3.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (4.9.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (0.28.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (8.5.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (15.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3->google-cloud-aiplatform) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3->google-cloud-aiplatform) (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/anaconda3/lib/python3.12/site-packages (from shapely<3.0.0->google-cloud-aiplatform) (1.26.4)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.3.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (0.14.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.8)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install --upgrade google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec7dbdf1-771b-40ea-a91a-04188698b59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.106.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059612dd-b084-4edf-b8d3-841b91b5611b",
   "metadata": {},
   "source": [
    "## Uniform Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3684cae0-fa35-4b3e-9068-6a85e0064ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = aiplatform.ImageDataset(f'projects/{project_id}/locations/us-central1/datasets/7519218623999639552')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56e8312c-5620-4b6f-af08-aa9bdc923d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display name: Circles_Uniform\n",
      "Resource name: projects/665016930796/locations/us-central1/datasets/7519218623999639552\n",
      "Metadata schema: gs://google-cloud-aiplatform/schema/dataset/metadata/image_1.0.0.yaml\n"
     ]
    }
   ],
   "source": [
    "print(f\"Display name: {dataset.display_name}\")\n",
    "print(f\"Resource name: {dataset.resource_name}\")\n",
    "print(f\"Metadata schema: {dataset.metadata_schema_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb004f2-4222-4f4c-b155-ad3ad971af01",
   "metadata": {},
   "source": [
    "### Getting subset of existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "271ba3d9-6504-4c95-961f-a21d2a85c3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export-data-Circles_Uniform-2025-08-04T04_10_37.205891Z_image_bounding_box_LLM_Images_Circles_iod-3721021126789300224_data-00001-of-00001.jsonl\n"
     ]
    }
   ],
   "source": [
    "!cd Data/annotation_sets && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54f03be8-d1cb-4be9-884f-967b2cb44466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zainabsiddiqui/Downloads/Data_Problems/LLM_Project'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae7a79fa-7f70-4feb-9860-1300417a80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_set_path = f\"{os.getcwd()}/Data/annotation_sets/export-data-Circles_Uniform-2025-08-04T04_10_37.205891Z_image_bounding_box_LLM_Images_Circles_iod-3721021126789300224_data-00001-of-00001.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4cdbfafa-4940-4d9e-9662-6f732152f767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"imageGcsUri\":\"gs://llm_shapes/r0_c5_t0_1.png\",\"boundingBoxAnnotations\":[{\"displayName\":\"Circle\",\"xMin\":0.29558541266794625,\"xMax\":0.418426103646833,\"yMin\":0.44529750479846447,\"yMax\":0.5681381957773513,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.2744721689059501,\"xMax\":0.40115163147792704,\"yMin\":0.5719769673704415,\"yMax\":0.6890595009596929,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.28982725527831094,\"xMax\":0.4222648752399232,\"yMin\":0.6276391554702495,\"yMax\":0.7543186180422264,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.6026871401151631,\"xMax\":0.7293666026871402,\"yMin\":0.7044145873320538,\"yMax\":0.8330134357005758,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.6833013435700576,\"xMax\":0.8061420345489443,\"yMin\":0.6717850287907869,\"yMax\":0.800383877159309,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}}],\"dataItemResourceLabels\":{}}\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(annot_set_path,\"r\") as file:\n",
    "    unif_circles_annot_dataset = file.readlines()\n",
    "\n",
    "unif_circles_annot_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4ef9f7c-46d7-4825-a8fb-29cd0b5c34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches\n",
    "batch_sizes = [5, 10, 20]\n",
    "\n",
    "for size in batch_sizes:\n",
    "    random.shuffle(unif_circles_annot_dataset)\n",
    "    with open(f\"{os.getcwd()}/Data/annotation_sets/uniform_circles_batch_{size}.jsonl\", \"w\") as out:\n",
    "        out.writelines(unif_circles_annot_dataset[:size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1ada8b2e-0136-4019-9e57-f9f8b66b913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_bucket_path = \"gs://llm_shapes/export-data-Circles_Uniform-2025-08-04T04:10:37.205891Z/image_bounding_box/LLM_Images_Circles_iod-3721021126789300224\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "691c0134-f6b8-4704-be24-931eefa8c5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export-data-Circles_Uniform-2025-08-04T04_10_37.205891Z_image_bounding_box_LLM_Images_Circles_iod-3721021126789300224_data-00001-of-00001.jsonl\n",
      "uniform_circles_batch_10.jsonl\n",
      "uniform_circles_batch_20.jsonl\n",
      "uniform_circles_batch_5.jsonl\n"
     ]
    }
   ],
   "source": [
    "!cd Data/annotation_sets && ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d8745-8f1d-4c64-88ca-b1b9f249b659",
   "metadata": {},
   "source": [
    "#### Create new subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78226dbf-5686-4da1-ad6d-1ae2ce1a939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ImageDataset\n",
      "Create ImageDataset backing LRO: projects/665016930796/locations/us-central1/datasets/5982488396461768704/operations/1107106469985124352\n",
      "ImageDataset created. Resource name: projects/665016930796/locations/us-central1/datasets/5982488396461768704\n",
      "To use this ImageDataset in another session:\n",
      "ds = aiplatform.ImageDataset('projects/665016930796/locations/us-central1/datasets/5982488396461768704')\n",
      "Importing ImageDataset data: projects/665016930796/locations/us-central1/datasets/5982488396461768704\n",
      "Import ImageDataset data backing LRO: projects/665016930796/locations/us-central1/datasets/5982488396461768704/operations/7487581242062274560\n",
      "ImageDataset data imported. Resource name: projects/665016930796/locations/us-central1/datasets/5982488396461768704\n",
      "New subset:  projects/665016930796/locations/us-central1/datasets/5982488396461768704 \n",
      "\n",
      "Creating ImageDataset\n",
      "Create ImageDataset backing LRO: projects/665016930796/locations/us-central1/datasets/1887308960298434560/operations/8620377285834309632\n",
      "ImageDataset created. Resource name: projects/665016930796/locations/us-central1/datasets/1887308960298434560\n",
      "To use this ImageDataset in another session:\n",
      "ds = aiplatform.ImageDataset('projects/665016930796/locations/us-central1/datasets/1887308960298434560')\n",
      "Importing ImageDataset data: projects/665016930796/locations/us-central1/datasets/1887308960298434560\n",
      "Import ImageDataset data backing LRO: projects/665016930796/locations/us-central1/datasets/1887308960298434560/operations/6774182913589116928\n",
      "ImageDataset data imported. Resource name: projects/665016930796/locations/us-central1/datasets/1887308960298434560\n",
      "New subset:  projects/665016930796/locations/us-central1/datasets/1887308960298434560 \n",
      "\n",
      "Creating ImageDataset\n",
      "Create ImageDataset backing LRO: projects/665016930796/locations/us-central1/datasets/2119525816084725760/operations/8562956390585335808\n",
      "ImageDataset created. Resource name: projects/665016930796/locations/us-central1/datasets/2119525816084725760\n",
      "To use this ImageDataset in another session:\n",
      "ds = aiplatform.ImageDataset('projects/665016930796/locations/us-central1/datasets/2119525816084725760')\n",
      "Importing ImageDataset data: projects/665016930796/locations/us-central1/datasets/2119525816084725760\n",
      "Import ImageDataset data backing LRO: projects/665016930796/locations/us-central1/datasets/2119525816084725760/operations/5645749731956097024\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 Invalid index file gs://llm_shapes/export-data-Circles_Uniform-2025-08-04T04:10:37.205891Z/image_bounding_box/LLM_Images_Circles_iod-3721021126789300224/uniform_circles_batch_20.jsonl line 11: {\"imageGcsUri\":\"gs://llm_shapes/r0_c6_t0.png\",\"boundingBoxAnnotations\":[{\"displayName\":\"Circle\",\"xMin\":0.44529750479846447,\"xMax\":0.6948176583493282,\"yMin\":0.19577735124760076,\"yMax\":0.43761996161228406,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.508637236084453,\"xMax\":0.7523992322456814,\"yMin\":0.23032629558541268,\"yMax\":0.47024952015355087,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5758157389635317,\"xMax\":0.8157389635316699,\"yMin\":0.30518234165067176,\"yMax\":0.5355086372360844,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.44529750479846447,\"xMax\":0.6928982725527831,\"yMin\":0.491362763915547,\"yMax\":0.727447216890595,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5028790786948176,\"xMax\":0.746641074856046,\"yMin\":0.5163147792706334,\"yMax\":0.7600767754318618,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5700575815738963,\"xMax\":0.8080614203454894,\"yMin\":0.5892514395393474,\"yMax\":0.8349328214971209,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}}],\"dataItemResourceLabels\":{}}{\"imageGcsUri\":\"gs://llm_shapes/r0_c1_t0_2.png\",\"boundingBoxAnnotations\":[{\"displayName\":\"Circle\",\"xMin\":0.45297504798464494,\"xMax\":0.5681381957773513,\"yMin\":0.23224568138195775,\"yMax\":0.345489443378119,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}}],\"dataItemResourceLabels\":{}} 3: Invalid index file gs://llm_shapes/export-data-Circles_Uniform-2025-08-04T04:10:37.205891Z/image_bounding_box/LLM_Images_Circles_iod-3721021126789300224/uniform_circles_batch_20.jsonl line 11: {\"imageGcsUri\":\"gs://llm_shapes/r0_c6_t0.png\",\"boundingBoxAnnotations\":[{\"displayName\":\"Circle\",\"xMin\":0.44529750479846447,\"xMax\":0.6948176583493282,\"yMin\":0.19577735124760076,\"yMax\":0.43761996161228406,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.508637236084453,\"xMax\":0.7523992322456814,\"yMin\":0.23032629558541268,\"yMax\":0.47024952015355087,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5758157389635317,\"xMax\":0.8157389635316699,\"yMin\":0.30518234165067176,\"yMax\":0.5355086372360844,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.44529750479846447,\"xMax\":0.6928982725527831,\"yMin\":0.491362763915547,\"yMax\":0.727447216890595,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5028790786948176,\"xMax\":0.746641074856046,\"yMin\":0.5163147792706334,\"yMax\":0.7600767754318618,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5700575815738963,\"xMax\":0.8080614203454894,\"yMin\":0.5892514395393474,\"yMax\":0.8349328214971209,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}}],\"dataItemResourceLabels\":{}}{\"imageGcsUri\":\"gs://llm_shapes/r0_c1_t0_2.png\",\"boundingBoxAnnotations\":[{\"displayName\":\"Circle\",\"xMin\":0.45297504798464494,\"xMax\":0.5681381957773513,\"yMin\":0.23224568138195775,\"yMax\":0.345489443378119,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}}],\"dataItemResourceLabels\":{}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m batch_sizes:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#var_name = f\"dataset_{num}\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     subset \u001b[38;5;241m=\u001b[39m aiplatform\u001b[38;5;241m.\u001b[39mImageDataset\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      4\u001b[0m         display_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munif_circles_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m         gcs_source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_bucket_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/uniform_circles_batch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m         import_schema_uri\u001b[38;5;241m=\u001b[39maiplatform\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mioformat\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mbounding_box,\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew subset: \u001b[39m\u001b[38;5;124m\"\u001b[39m,subset\u001b[38;5;241m.\u001b[39mresource_name,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/aiplatform/datasets/image_dataset.py:180\u001b[0m, in \u001b[0;36mImageDataset.create\u001b[0;34m(cls, display_name, gcs_source, import_schema_uri, data_item_labels, project, location, credentials, request_metadata, labels, encryption_spec_key_name, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m metadata_schema_uri \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mimage\n\u001b[1;32m    173\u001b[0m datasource \u001b[38;5;241m=\u001b[39m _datasources\u001b[38;5;241m.\u001b[39mcreate_datasource(\n\u001b[1;32m    174\u001b[0m     metadata_schema_uri\u001b[38;5;241m=\u001b[39mmetadata_schema_uri,\n\u001b[1;32m    175\u001b[0m     import_schema_uri\u001b[38;5;241m=\u001b[39mimport_schema_uri,\n\u001b[1;32m    176\u001b[0m     gcs_source\u001b[38;5;241m=\u001b[39mgcs_source,\n\u001b[1;32m    177\u001b[0m     data_item_labels\u001b[38;5;241m=\u001b[39mdata_item_labels,\n\u001b[1;32m    178\u001b[0m )\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_create_and_import(\n\u001b[1;32m    181\u001b[0m     api_client\u001b[38;5;241m=\u001b[39mapi_client,\n\u001b[1;32m    182\u001b[0m     parent\u001b[38;5;241m=\u001b[39minitializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mcommon_location_path(\n\u001b[1;32m    183\u001b[0m         project\u001b[38;5;241m=\u001b[39mproject, location\u001b[38;5;241m=\u001b[39mlocation\n\u001b[1;32m    184\u001b[0m     ),\n\u001b[1;32m    185\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mdisplay_name,\n\u001b[1;32m    186\u001b[0m     metadata_schema_uri\u001b[38;5;241m=\u001b[39mmetadata_schema_uri,\n\u001b[1;32m    187\u001b[0m     datasource\u001b[38;5;241m=\u001b[39mdatasource,\n\u001b[1;32m    188\u001b[0m     project\u001b[38;5;241m=\u001b[39mproject \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mproject,\n\u001b[1;32m    189\u001b[0m     location\u001b[38;5;241m=\u001b[39mlocation \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mlocation,\n\u001b[1;32m    190\u001b[0m     credentials\u001b[38;5;241m=\u001b[39mcredentials \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mcredentials,\n\u001b[1;32m    191\u001b[0m     request_metadata\u001b[38;5;241m=\u001b[39mrequest_metadata,\n\u001b[1;32m    192\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    193\u001b[0m     encryption_spec\u001b[38;5;241m=\u001b[39minitializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mget_encryption_spec(\n\u001b[1;32m    194\u001b[0m         encryption_spec_key_name\u001b[38;5;241m=\u001b[39mencryption_spec_key_name\n\u001b[1;32m    195\u001b[0m     ),\n\u001b[1;32m    196\u001b[0m     sync\u001b[38;5;241m=\u001b[39msync,\n\u001b[1;32m    197\u001b[0m     create_request_timeout\u001b[38;5;241m=\u001b[39mcreate_request_timeout,\n\u001b[1;32m    198\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:863\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    862\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    865\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    866\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/aiplatform/datasets/dataset.py:369\u001b[0m, in \u001b[0;36m_Dataset._create_and_import\u001b[0;34m(cls, api_client, parent, display_name, metadata_schema_uri, datasource, project, location, credentials, request_metadata, labels, encryption_spec, sync, create_request_timeout, import_request_timeout)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# Import if import datasource is DatasourceImportable\u001b[39;00m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(datasource, _datasources\u001b[38;5;241m.\u001b[39mDatasourceImportable):\n\u001b[0;32m--> 369\u001b[0m     dataset_obj\u001b[38;5;241m.\u001b[39m_import_and_wait(\n\u001b[1;32m    370\u001b[0m         datasource, import_request_timeout\u001b[38;5;241m=\u001b[39mimport_request_timeout\n\u001b[1;32m    371\u001b[0m     )\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset_obj\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/aiplatform/datasets/dataset.py:394\u001b[0m, in \u001b[0;36m_Dataset._import_and_wait\u001b[0;34m(self, datasource, import_request_timeout)\u001b[0m\n\u001b[1;32m    386\u001b[0m import_lro \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_import(\n\u001b[1;32m    387\u001b[0m     datasource\u001b[38;5;241m=\u001b[39mdatasource, import_request_timeout\u001b[38;5;241m=\u001b[39mimport_request_timeout\n\u001b[1;32m    388\u001b[0m )\n\u001b[1;32m    390\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_started_against_resource_with_lro(\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImport\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, import_lro\n\u001b[1;32m    392\u001b[0m )\n\u001b[0;32m--> 394\u001b[0m import_lro\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    396\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_completed_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimported\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/api_core/future/polling.py:261\u001b[0m, in \u001b[0;36mPollingFuture.result\u001b[0;34m(self, timeout, retry, polling)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking_poll(timeout\u001b[38;5;241m=\u001b[39mtimeout, retry\u001b[38;5;241m=\u001b[39mretry, polling\u001b[38;5;241m=\u001b[39mpolling)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raising-bad-type\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Pylint doesn't recognize that this is valid in this case.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 Invalid index file gs://llm_shapes/export-data-Circles_Uniform-2025-08-04T04:10:37.205891Z/image_bounding_box/LLM_Images_Circles_iod-3721021126789300224/uniform_circles_batch_20.jsonl line 11: {\"imageGcsUri\":\"gs://llm_shapes/r0_c6_t0.png\",\"boundingBoxAnnotations\":[{\"displayName\":\"Circle\",\"xMin\":0.44529750479846447,\"xMax\":0.6948176583493282,\"yMin\":0.19577735124760076,\"yMax\":0.43761996161228406,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.508637236084453,\"xMax\":0.7523992322456814,\"yMin\":0.23032629558541268,\"yMax\":0.47024952015355087,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5758157389635317,\"xMax\":0.8157389635316699,\"yMin\":0.30518234165067176,\"yMax\":0.5355086372360844,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.44529750479846447,\"xMax\":0.6928982725527831,\"yMin\":0.491362763915547,\"yMax\":0.727447216890595,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5028790786948176,\"xMax\":0.746641074856046,\"yMin\":0.5163147792706334,\"yMax\":0.7600767754318618,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5700575815738963,\"xMax\":0.8080614203454894,\"yMin\":0.5892514395393474,\"yMax\":0.8349328214971209,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}}],\"dataItemResourceLabels\":{}}{\"imageGcsUri\":\"gs://llm_shapes/r0_c1_t0_2.png\",\"boundingBoxAnnotations\":[{\"displayName\":\"Circle\",\"xMin\":0.45297504798464494,\"xMax\":0.5681381957773513,\"yMin\":0.23224568138195775,\"yMax\":0.345489443378119,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}}],\"dataItemResourceLabels\":{}} 3: Invalid index file gs://llm_shapes/export-data-Circles_Uniform-2025-08-04T04:10:37.205891Z/image_bounding_box/LLM_Images_Circles_iod-3721021126789300224/uniform_circles_batch_20.jsonl line 11: {\"imageGcsUri\":\"gs://llm_shapes/r0_c6_t0.png\",\"boundingBoxAnnotations\":[{\"displayName\":\"Circle\",\"xMin\":0.44529750479846447,\"xMax\":0.6948176583493282,\"yMin\":0.19577735124760076,\"yMax\":0.43761996161228406,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.508637236084453,\"xMax\":0.7523992322456814,\"yMin\":0.23032629558541268,\"yMax\":0.47024952015355087,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5758157389635317,\"xMax\":0.8157389635316699,\"yMin\":0.30518234165067176,\"yMax\":0.5355086372360844,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.44529750479846447,\"xMax\":0.6928982725527831,\"yMin\":0.491362763915547,\"yMax\":0.727447216890595,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5028790786948176,\"xMax\":0.746641074856046,\"yMin\":0.5163147792706334,\"yMax\":0.7600767754318618,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}},{\"displayName\":\"Circle\",\"xMin\":0.5700575815738963,\"xMax\":0.8080614203454894,\"yMin\":0.5892514395393474,\"yMax\":0.8349328214971209,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}}],\"dataItemResourceLabels\":{}}{\"imageGcsUri\":\"gs://llm_shapes/r0_c1_t0_2.png\",\"boundingBoxAnnotations\":[{\"displayName\":\"Circle\",\"xMin\":0.45297504798464494,\"xMax\":0.5681381957773513,\"yMin\":0.23224568138195775,\"yMax\":0.345489443378119,\"annotationResourceLabels\":{\"aiplatform.googleapis.com/annotation_set_name\":\"3721021126789300224\"}}],\"dataItemResourceLabels\":{}}"
     ]
    }
   ],
   "source": [
    "for num in batch_sizes:\n",
    "    #var_name = f\"dataset_{num}\"\n",
    "    subset = aiplatform.ImageDataset.create(\n",
    "        display_name=f\"unif_circles_{num}\",\n",
    "        gcs_source=f\"{json_bucket_path}/uniform_circles_batch_{num}.jsonl\",\n",
    "        import_schema_uri=aiplatform.schema.dataset.ioformat.image.bounding_box,\n",
    "    )\n",
    "    print(\"New subset: \",subset.resource_name,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bed83d-f1d1-4ab7-a799-1fbdec520519",
   "metadata": {},
   "source": [
    "    full dataset can be used as third subset instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9a919b3d-9302-4e3e-b1a7-4d5c8532f75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display name: unif_circles_5\n",
      "Resource name: projects/665016930796/locations/us-central1/datasets/5982488396461768704\n",
      "Metadata schema: gs://google-cloud-aiplatform/schema/dataset/metadata/image_1.0.0.yaml\n"
     ]
    }
   ],
   "source": [
    "dataset_5 = aiplatform.ImageDataset(\"projects/665016930796/locations/us-central1/datasets/5982488396461768704\")\n",
    "\n",
    "print(f\"Display name: {dataset_5.display_name}\")\n",
    "print(f\"Resource name: {dataset_5.resource_name}\")\n",
    "print(f\"Metadata schema: {dataset_5.metadata_schema_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c8529f23-076b-497f-9225-ac52316154e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display name: unif_circles_10\n",
      "Resource name: projects/665016930796/locations/us-central1/datasets/1887308960298434560\n",
      "Metadata schema: gs://google-cloud-aiplatform/schema/dataset/metadata/image_1.0.0.yaml\n"
     ]
    }
   ],
   "source": [
    "dataset_10 = aiplatform.ImageDataset(\"projects/665016930796/locations/us-central1/datasets/1887308960298434560\")\n",
    "\n",
    "print(f\"Display name: {dataset_10.display_name}\")\n",
    "print(f\"Resource name: {dataset_10.resource_name}\")\n",
    "print(f\"Metadata schema: {dataset_10.metadata_schema_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb05bd1-08de-4a09-9176-d943ed0ccf7f",
   "metadata": {},
   "source": [
    "### Modeling (NOT CORRECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "741ac7e1-1a94-42fe-9098-edb225710358",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.AutoMLImageTrainingJob(\n",
    "    display_name=\"fine-tune-batch-5\",\n",
    "    prediction_type=\"object_detection\",\n",
    "    model_type=\"CLOUD\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "33c6029d-79d9-41c1-abf7-22b68639df75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/4560879321274646528?project=665016930796\n",
      "AutoMLImageTrainingJob projects/665016930796/locations/us-central1/trainingPipelines/4560879321274646528 current state:\n",
      "2\n",
      "AutoMLImageTrainingJob projects/665016930796/locations/us-central1/trainingPipelines/4560879321274646528 current state:\n",
      "2\n",
      "AutoMLImageTrainingJob projects/665016930796/locations/us-central1/trainingPipelines/4560879321274646528 current state:\n",
      "3\n",
      "AutoMLImageTrainingJob projects/665016930796/locations/us-central1/trainingPipelines/4560879321274646528 current state:\n",
      "3\n",
      "AutoMLImageTrainingJob projects/665016930796/locations/us-central1/trainingPipelines/4560879321274646528 current state:\n",
      "3\n",
      "AutoMLImageTrainingJob projects/665016930796/locations/us-central1/trainingPipelines/4560879321274646528 current state:\n",
      "3\n",
      "AutoMLImageTrainingJob projects/665016930796/locations/us-central1/trainingPipelines/4560879321274646528 current state:\n",
      "3\n",
      "AutoMLImageTrainingJob projects/665016930796/locations/us-central1/trainingPipelines/4560879321274646528 current state:\n",
      "3\n",
      "AutoMLImageTrainingJob projects/665016930796/locations/us-central1/trainingPipelines/4560879321274646528 current state:\n",
      "3\n",
      "AutoMLImageTrainingJob projects/665016930796/locations/us-central1/trainingPipelines/4560879321274646528 current state:\n",
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m      2\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset_5,\n\u001b[1;32m      3\u001b[0m     model_display_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_batch_5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     training_fraction_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[1;32m      5\u001b[0m     validation_fraction_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m      6\u001b[0m     test_fraction_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m      7\u001b[0m     sync\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/aiplatform/training_jobs.py:7206\u001b[0m, in \u001b[0;36mAutoMLImageTrainingJob.run\u001b[0;34m(self, dataset, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, budget_milli_node_hours, model_display_name, model_labels, model_id, parent_model, is_default_version, model_version_aliases, model_version_description, disable_early_stopping, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m   7203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_run:\n\u001b[1;32m   7204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoML Image Training has already run.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(\n\u001b[1;32m   7207\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m   7208\u001b[0m     base_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_model,\n\u001b[1;32m   7209\u001b[0m     incremental_train_base_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_incremental_train_base_model,\n\u001b[1;32m   7210\u001b[0m     training_fraction_split\u001b[38;5;241m=\u001b[39mtraining_fraction_split,\n\u001b[1;32m   7211\u001b[0m     validation_fraction_split\u001b[38;5;241m=\u001b[39mvalidation_fraction_split,\n\u001b[1;32m   7212\u001b[0m     test_fraction_split\u001b[38;5;241m=\u001b[39mtest_fraction_split,\n\u001b[1;32m   7213\u001b[0m     training_filter_split\u001b[38;5;241m=\u001b[39mtraining_filter_split,\n\u001b[1;32m   7214\u001b[0m     validation_filter_split\u001b[38;5;241m=\u001b[39mvalidation_filter_split,\n\u001b[1;32m   7215\u001b[0m     test_filter_split\u001b[38;5;241m=\u001b[39mtest_filter_split,\n\u001b[1;32m   7216\u001b[0m     budget_milli_node_hours\u001b[38;5;241m=\u001b[39mbudget_milli_node_hours,\n\u001b[1;32m   7217\u001b[0m     model_display_name\u001b[38;5;241m=\u001b[39mmodel_display_name,\n\u001b[1;32m   7218\u001b[0m     model_labels\u001b[38;5;241m=\u001b[39mmodel_labels,\n\u001b[1;32m   7219\u001b[0m     model_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m   7220\u001b[0m     parent_model\u001b[38;5;241m=\u001b[39mparent_model,\n\u001b[1;32m   7221\u001b[0m     is_default_version\u001b[38;5;241m=\u001b[39mis_default_version,\n\u001b[1;32m   7222\u001b[0m     model_version_aliases\u001b[38;5;241m=\u001b[39mmodel_version_aliases,\n\u001b[1;32m   7223\u001b[0m     model_version_description\u001b[38;5;241m=\u001b[39mmodel_version_description,\n\u001b[1;32m   7224\u001b[0m     disable_early_stopping\u001b[38;5;241m=\u001b[39mdisable_early_stopping,\n\u001b[1;32m   7225\u001b[0m     sync\u001b[38;5;241m=\u001b[39msync,\n\u001b[1;32m   7226\u001b[0m     create_request_timeout\u001b[38;5;241m=\u001b[39mcreate_request_timeout,\n\u001b[1;32m   7227\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/aiplatform/base.py:863\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    862\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    865\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    866\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/aiplatform/training_jobs.py:7443\u001b[0m, in \u001b[0;36mAutoMLImageTrainingJob._run\u001b[0;34m(self, dataset, base_model, incremental_train_base_model, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, budget_milli_node_hours, model_display_name, model_labels, model_id, parent_model, is_default_version, model_version_aliases, model_version_description, disable_early_stopping, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m   7440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tunable_parameter_dict:\n\u001b[1;32m   7441\u001b[0m     training_task_inputs_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtunableParameter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tunable_parameter_dict\n\u001b[0;32m-> 7443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_job(\n\u001b[1;32m   7444\u001b[0m     training_task_definition\u001b[38;5;241m=\u001b[39mtraining_task_definition,\n\u001b[1;32m   7445\u001b[0m     training_task_inputs\u001b[38;5;241m=\u001b[39mtraining_task_inputs_dict,\n\u001b[1;32m   7446\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m   7447\u001b[0m     training_fraction_split\u001b[38;5;241m=\u001b[39mtraining_fraction_split,\n\u001b[1;32m   7448\u001b[0m     validation_fraction_split\u001b[38;5;241m=\u001b[39mvalidation_fraction_split,\n\u001b[1;32m   7449\u001b[0m     test_fraction_split\u001b[38;5;241m=\u001b[39mtest_fraction_split,\n\u001b[1;32m   7450\u001b[0m     training_filter_split\u001b[38;5;241m=\u001b[39mtraining_filter_split,\n\u001b[1;32m   7451\u001b[0m     validation_filter_split\u001b[38;5;241m=\u001b[39mvalidation_filter_split,\n\u001b[1;32m   7452\u001b[0m     test_filter_split\u001b[38;5;241m=\u001b[39mtest_filter_split,\n\u001b[1;32m   7453\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_tbt,\n\u001b[1;32m   7454\u001b[0m     model_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m   7455\u001b[0m     parent_model\u001b[38;5;241m=\u001b[39mparent_model,\n\u001b[1;32m   7456\u001b[0m     is_default_version\u001b[38;5;241m=\u001b[39mis_default_version,\n\u001b[1;32m   7457\u001b[0m     model_version_aliases\u001b[38;5;241m=\u001b[39mmodel_version_aliases,\n\u001b[1;32m   7458\u001b[0m     model_version_description\u001b[38;5;241m=\u001b[39mmodel_version_description,\n\u001b[1;32m   7459\u001b[0m     create_request_timeout\u001b[38;5;241m=\u001b[39mcreate_request_timeout,\n\u001b[1;32m   7460\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/aiplatform/training_jobs.py:855\u001b[0m, in \u001b[0;36m_TrainingJob._run_job\u001b[0;34m(self, training_task_definition, training_task_inputs, dataset, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, predefined_split_column_name, timestamp_split_column_name, annotation_schema_uri, model, model_id, parent_model, is_default_version, model_version_aliases, model_version_description, gcs_destination_uri_prefix, bigquery_destination, create_request_timeout, block)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m training_pipeline\n\u001b[1;32m    853\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mView Training:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dashboard_uri())\n\u001b[0;32m--> 855\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model(block\u001b[38;5;241m=\u001b[39mblock)\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining did not produce a Managed Model returning None. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_upload_fail_string\n\u001b[1;32m    861\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/aiplatform/training_jobs.py:942\u001b[0m, in \u001b[0;36m_TrainingJob._get_model\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to get and instantiate the Model to Upload.\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;124;03m    RuntimeError: If Training failed.\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_block_until_complete()\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_failed:\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    946\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Pipeline \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresource_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed. No model available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    947\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/google/cloud/aiplatform/training_jobs.py:983\u001b[0m, in \u001b[0;36m_TrainingJob._block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m         previous_time \u001b[38;5;241m=\u001b[39m current_time\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_callback()\n\u001b[0;32m--> 983\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(_JOB_WAIT_TIME)\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_failure()\n\u001b[1;32m    987\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_completed_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = job.run(\n",
    "    dataset=dataset_5,\n",
    "    model_display_name=\"model_batch_5\",\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    "    sync=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34613e10-de23-43fa-b301-a6dafa54a04b",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b783f16-ada9-4689-84a0-dde711cd2d8e",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8419afb6-33e4-4a6e-92b9-500f2dd7b655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pydantic/_internal/_fields.py:184: UserWarning: Field name \"name\" shadows an attribute in parent \"Operation\"; \n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pydantic/_internal/_fields.py:184: UserWarning: Field name \"metadata\" shadows an attribute in parent \"Operation\"; \n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pydantic/_internal/_fields.py:184: UserWarning: Field name \"done\" shadows an attribute in parent \"Operation\"; \n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pydantic/_internal/_fields.py:184: UserWarning: Field name \"error\" shadows an attribute in parent \"Operation\"; \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99adbef9-4707-47a4-b053-05c1e850712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import vertexai\n",
    "from vertexai.tuning import sft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "35a46c79-1f2b-4d11-8b0e-28f891882eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export-data-Circles_Uniform-2025-08-04T04_10_37.205891Z_image_bounding_box_LLM_Images_Circles_iod-3721021126789300224_data-00001-of-00001.jsonl\n",
      "uniform_circles_batch_10.jsonl\n",
      "uniform_circles_batch_20.jsonl\n",
      "uniform_circles_batch_5.jsonl\n"
     ]
    }
   ],
   "source": [
    "! ls Data/annotation_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f445aa71-e207-47d3-b97f-4881bffb417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files():\n",
    "    ! ls Data/annotation_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "772ac08b-fe2b-4e0a-8b36-47d399381003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get image paths \n",
    "with open(f\"{os.getcwd()}/Data/annotation_sets/uniform_circles_batch_10.jsonl\", \"r\") as f:\n",
    "    records = [json.loads(line) for line in f]\n",
    "\n",
    "image_uris = [record[\"imageGcsUri\"] for record in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d94c6304-6778-4b5f-af03-bcaf51ba5c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(json_file_name):\n",
    "    \"\"\"Returns list with image file paths from google cloud dataset\"\"\"\n",
    "    with open(f\"{os.getcwd()}/Data/annotation_sets/{json_file_name}\", \"r\") as f:\n",
    "        records = [json.loads(line) for line in f]\n",
    "    return [record[\"imageGcsUri\"] for record in records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d7672b42-f633-4e77-a5a1-502b578b6665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://llm_shapes/r0_c8_t0_4.png',\n",
       " 'gs://llm_shapes/r0_c1_t0_3.png',\n",
       " 'gs://llm_shapes/r0_c2_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c7_t0.png',\n",
       " 'gs://llm_shapes/r0_c2_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c4_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_4.png',\n",
       " 'gs://llm_shapes/r0_c1_t0_5.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c5_t0.png']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "13e7c869-ab99-471e-a486-964965ee5f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_uris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ecc9c63a-1cb7-4d1f-89fb-fa4e6b6eb36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-2.0-flash-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "28e396bd-82fb-4ae9-bfd5-3c82732cdb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bacf468c-90ce-4c2f-8509-1216da5230ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses=pd.DataFrame(columns=[\"pic_id\",\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f2993cdb-7b4e-4a90-ab51-10d36a72f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b7c4f678-36ac-4d1b-8db6-3706df391740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://llm_shapes/r0_c8_t0_4.png -> There are 8 circles in the image.\n",
      "gs://llm_shapes/r0_c1_t0_3.png -> There is 1 circle in the image.\n",
      "gs://llm_shapes/r0_c2_t0_1.png -> There are 2 circles in the image.\n",
      "gs://llm_shapes/r0_c7_t0.png -> There are 6 circles in the image.\n",
      "gs://llm_shapes/r0_c2_t0_2.png -> There are 2 circles in the image.\n",
      "gs://llm_shapes/r0_c4_t0_1.png -> There are 4 circles in the image.\n",
      "gs://llm_shapes/r0_c7_t0_4.png -> There are 7 circles in the image.\n",
      "gs://llm_shapes/r0_c1_t0_5.png -> There is 1 circle in the image.\n",
      "gs://llm_shapes/r0_c7_t0_1.png -> There are 7 circles in the image.\n",
      "gs://llm_shapes/r0_c5_t0.png -> There are 5 circles in the image.\n"
     ]
    }
   ],
   "source": [
    "for uri in image_uris:\n",
    "    image = Part.from_uri(uri, mime_type=\"image/png\")  # adjust mime type if needed\n",
    "    prompt = \"Count the circles in this image.\"\n",
    "    response = model.generate_content([prompt, image])\n",
    "    response_list.append({\"pic_id\":uri,\"response\":response.text})\n",
    "    responses = pd.DataFrame(response_list)\n",
    "    print(uri, \"->\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "628586f8-13f7-4fdc-87b0-264736d73ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pic_id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://llm_shapes/r0_c8_t0_4.png</td>\n",
       "      <td>There are 8 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://llm_shapes/r0_c1_t0_3.png</td>\n",
       "      <td>There is 1 circle in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://llm_shapes/r0_c2_t0_1.png</td>\n",
       "      <td>There are 2 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://llm_shapes/r0_c7_t0.png</td>\n",
       "      <td>There are 6 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://llm_shapes/r0_c2_t0_2.png</td>\n",
       "      <td>There are 2 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gs://llm_shapes/r0_c4_t0_1.png</td>\n",
       "      <td>There are 4 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_4.png</td>\n",
       "      <td>There are 7 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gs://llm_shapes/r0_c1_t0_5.png</td>\n",
       "      <td>There is 1 circle in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_1.png</td>\n",
       "      <td>There are 7 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gs://llm_shapes/r0_c5_t0.png</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           pic_id                           response\n",
       "0  gs://llm_shapes/r0_c8_t0_4.png  There are 8 circles in the image.\n",
       "1  gs://llm_shapes/r0_c1_t0_3.png    There is 1 circle in the image.\n",
       "2  gs://llm_shapes/r0_c2_t0_1.png  There are 2 circles in the image.\n",
       "3    gs://llm_shapes/r0_c7_t0.png  There are 6 circles in the image.\n",
       "4  gs://llm_shapes/r0_c2_t0_2.png  There are 2 circles in the image.\n",
       "5  gs://llm_shapes/r0_c4_t0_1.png  There are 4 circles in the image.\n",
       "6  gs://llm_shapes/r0_c7_t0_4.png  There are 7 circles in the image.\n",
       "7  gs://llm_shapes/r0_c1_t0_5.png    There is 1 circle in the image.\n",
       "8  gs://llm_shapes/r0_c7_t0_1.png  There are 7 circles in the image.\n",
       "9    gs://llm_shapes/r0_c5_t0.png  There are 5 circles in the image."
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0b9fad-97d8-4bb5-83ce-735751817a54",
   "metadata": {},
   "source": [
    "    9/10 correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1a66762c-9567-491f-95b4-9adcc5dd1e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://llm_shapes/r0_c1_t0_4.png -> There is 1 circle in the image.\n",
      "gs://llm_shapes/r0_c6_t0_2.png -> There are 5 circles in the image.\n",
      "gs://llm_shapes/r0_c7_t0_5.png -> There are 6 circles in the image.\n",
      "gs://llm_shapes/r0_c4_t0_5.png -> There are 5 circles in the image.\n",
      "gs://llm_shapes/r0_c6_t0_3.png -> There are 6 circles in the image.\n"
     ]
    }
   ],
   "source": [
    "uris_5 = get_image_paths(\"uniform_circles_batch_5.jsonl\")\n",
    "\n",
    "for uri in uris_5:\n",
    "    image = Part.from_uri(uri, mime_type=\"image/png\") \n",
    "    prompt = \"Count the circles in this image.\"\n",
    "    response = model.generate_content([prompt, image])\n",
    "    response_list.append({\"pic_id\":uri,\"response\":response.text})\n",
    "    responses = pd.DataFrame(response_list)\n",
    "    print(uri, \"->\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e4e62a-e10c-4018-afa7-fb3ac47ef1a9",
   "metadata": {},
   "source": [
    "    2/5 correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1a591ccc-3878-404d-933b-52bd5434a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export-data-Circles_Uniform-2025-08-04T04_10_37.205891Z_image_bounding_box_LLM_Images_Circles_iod-3721021126789300224_data-00001-of-00001.jsonl\n",
      "export-data-Circles_Variety-2025-08-11T10_41_57.250769Z_image_bounding_box_LLM_Images_Circles_Variety_iod-998595152043835392_data-00001-of-00001.jsonl\n",
      "uniform_circles_batch_10.jsonl\n",
      "uniform_circles_batch_20.jsonl\n",
      "uniform_circles_batch_5.jsonl\n"
     ]
    }
   ],
   "source": [
    "list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5e9104e-c108-490d-8b3d-ba73d63b8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "variety_circles = get_image_paths(\"export-data-Circles_Variety-2025-08-11T10_41_57.250769Z_image_bounding_box_LLM_Images_Circles_Variety_iod-998595152043835392_data-00001-of-00001.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bc4d47d5-6bdc-4cb8-b8a0-7ef0680b862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://llm_shapes/r0_c5_t0.png -> There are 5 circles in the image.\n",
      "gs://llm_shapes/r0_c7_t0_2.png -> There are 7 circles in the image.\n",
      "gs://llm_shapes/r0_c6_t0_2.png -> There are 5 circles in the image.\n",
      "gs://llm_shapes/r0_c7_t0_4.png -> There are 7 circles in the image.\n",
      "gs://llm_shapes/r0_c7_t0_4.png -> There are 7 circles in the image.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "uris_5 = random.choices(variety_circles,k=5)\n",
    "\n",
    "for uri in uris_5:\n",
    "    image = Part.from_uri(uri, mime_type=\"image/png\") \n",
    "    prompt = \"Count the circles in this image.\"\n",
    "    response = model.generate_content([prompt, image])\n",
    "    response_list.append({\"pic_id\":uri,\"response\":response.text,\"notes\":\"Differently sized circles\"})\n",
    "    responses = pd.DataFrame(response_list)\n",
    "    print(uri, \"->\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3c46a1-01c4-4c54-ab80-55e855bf9fde",
   "metadata": {},
   "source": [
    "    4/5 correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "88f1a63d-01ac-49c9-b0c7-749433274f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://llm_shapes/r0_c8_t0_4.png', 'gs://llm_shapes/r0_c1_t0_3.png', 'gs://llm_shapes/r0_c2_t0_1.png', 'gs://llm_shapes/r0_c7_t0.png', 'gs://llm_shapes/r0_c2_t0_2.png', 'gs://llm_shapes/r0_c4_t0_1.png', 'gs://llm_shapes/r0_c7_t0_4.png', 'gs://llm_shapes/r0_c1_t0_5.png', 'gs://llm_shapes/r0_c7_t0_1.png', 'gs://llm_shapes/r0_c5_t0.png', 'gs://llm_shapes/r0_c1_t0_4.png', 'gs://llm_shapes/r0_c6_t0_2.png', 'gs://llm_shapes/r0_c7_t0_5.png', 'gs://llm_shapes/r0_c4_t0_5.png', 'gs://llm_shapes/r0_c6_t0_3.png', 'gs://llm_shapes/r0_c5_t0.png', 'gs://llm_shapes/r0_c7_t0_2.png', 'gs://llm_shapes/r0_c6_t0_2.png', 'gs://llm_shapes/r0_c7_t0_4.png', 'gs://llm_shapes/r0_c7_t0_4.png']\n"
     ]
    }
   ],
   "source": [
    "list(responses.pic_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "399880b8-a421-46f0-be68-64ff8ccbb724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pic_id': ['gs://llm_shapes/r0_c8_t0_4.png',\n",
       "  'gs://llm_shapes/r0_c1_t0_3.png',\n",
       "  'gs://llm_shapes/r0_c2_t0_1.png',\n",
       "  'gs://llm_shapes/r0_c7_t0.png',\n",
       "  'gs://llm_shapes/r0_c2_t0_2.png',\n",
       "  'gs://llm_shapes/r0_c4_t0_1.png',\n",
       "  'gs://llm_shapes/r0_c7_t0_4.png',\n",
       "  'gs://llm_shapes/r0_c1_t0_5.png',\n",
       "  'gs://llm_shapes/r0_c7_t0_1.png',\n",
       "  'gs://llm_shapes/r0_c5_t0.png',\n",
       "  'gs://llm_shapes/r0_c1_t0_4.png',\n",
       "  'gs://llm_shapes/r0_c6_t0_2.png',\n",
       "  'gs://llm_shapes/r0_c7_t0_5.png',\n",
       "  'gs://llm_shapes/r0_c4_t0_5.png',\n",
       "  'gs://llm_shapes/r0_c6_t0_3.png',\n",
       "  'gs://llm_shapes/r0_c5_t0.png',\n",
       "  'gs://llm_shapes/r0_c7_t0_2.png',\n",
       "  'gs://llm_shapes/r0_c6_t0_2.png',\n",
       "  'gs://llm_shapes/r0_c7_t0_4.png',\n",
       "  'gs://llm_shapes/r0_c7_t0_4.png',\n",
       "  'gs://llm_shapes/r0_c1_t0_1.png',\n",
       "  'gs://llm_shapes/r0_c3_t0.png',\n",
       "  'gs://llm_shapes/r0_c1_t0.png',\n",
       "  'gs://llm_shapes/r0_c6_t0_1.png',\n",
       "  'gs://llm_shapes/r0_c5_t0_1.png',\n",
       "  'gs://llm_shapes/r0_c0_t0_3.png',\n",
       "  'gs://llm_shapes/r0_c4_t0_4.png'],\n",
       " 'response': ['There are 8 circles in the image.',\n",
       "  'There is 1 circle in the image.',\n",
       "  'There are 2 circles in the image.',\n",
       "  'There are 6 circles in the image.',\n",
       "  'There are 2 circles in the image.',\n",
       "  'There are 4 circles in the image.',\n",
       "  'There are 7 circles in the image.',\n",
       "  'There is 1 circle in the image.',\n",
       "  'There are 7 circles in the image.',\n",
       "  'There are 5 circles in the image.',\n",
       "  'There is 1 circle in the image.',\n",
       "  'There are 5 circles in the image.',\n",
       "  'There are 6 circles in the image.',\n",
       "  'There are 5 circles in the image.',\n",
       "  'There are 6 circles in the image.',\n",
       "  'There are 5 circles in the image.',\n",
       "  'There are 7 circles in the image.',\n",
       "  'There are 5 circles in the image.',\n",
       "  'There are 7 circles in the image.',\n",
       "  'There are 7 circles in the image.',\n",
       "  'There is 1 circle in the image.',\n",
       "  'There are 3 circles in the image.',\n",
       "  'There is 1 circle in the image.',\n",
       "  'There are 6 circles in the image.',\n",
       "  'There are 5 circles in the image.',\n",
       "  'There are no circles in this image.',\n",
       "  'There are 4 circles in the image.'],\n",
       " 'notes': [nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  nan,\n",
       "  'Differently sized circles',\n",
       "  'Differently sized circles',\n",
       "  'Differently sized circles',\n",
       "  'Differently sized circles',\n",
       "  'Differently sized circles',\n",
       "  'Differently sized circles',\n",
       "  'Differently sized circles',\n",
       "  'Differently sized circles',\n",
       "  'Differently sized circles',\n",
       "  'Differently sized circles',\n",
       "  'Differently sized circles',\n",
       "  'Differently sized circles']}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = responses.to_dict(orient=\"list\")\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cd166949-2b78-47f0-8658-bbaa89a86ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://llm_shapes/r0_c1_t0_1.png -> There is 1 circle in the image.\n",
      "gs://llm_shapes/r0_c3_t0.png -> There are 3 circles in the image.\n",
      "gs://llm_shapes/r0_c1_t0.png -> There is 1 circle in the image.\n",
      "gs://llm_shapes/r0_c6_t0_1.png -> There are 6 circles in the image.\n",
      "gs://llm_shapes/r0_c5_t0_1.png -> There are 5 circles in the image.\n",
      "gs://llm_shapes/r0_c0_t0_3.png -> There are no circles in this image.\n",
      "gs://llm_shapes/r0_c4_t0_4.png -> There are 4 circles in the image.\n"
     ]
    }
   ],
   "source": [
    "uris_5 = random.choices(variety_circles,k=10)\n",
    "\n",
    "for uri in uris_5:\n",
    "    if uri in list(responses.pic_id):\n",
    "        continue\n",
    "    image = Part.from_uri(uri, mime_type=\"image/png\") \n",
    "    prompt = \"Count the circles in this image.\"\n",
    "    response = model.generate_content([prompt, image])\n",
    "    response_list.append({\"pic_id\":uri,\"response\":response.text,\"notes\":\"Differently sized circles\"})\n",
    "    responses = pd.DataFrame(response_list)\n",
    "    print(uri, \"->\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5824a-a9e2-4b96-8286-8be56578ae1b",
   "metadata": {},
   "source": [
    "    7/7 correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dffaa017-5299-49ff-99ca-ea81e2337ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pic_id</th>\n",
       "      <th>response</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gs://llm_shapes/r0_c6_t0_2.png</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_4.png</td>\n",
       "      <td>There are 7 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_4.png</td>\n",
       "      <td>There are 7 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gs://llm_shapes/r0_c1_t0_1.png</td>\n",
       "      <td>There is 1 circle in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gs://llm_shapes/r0_c3_t0.png</td>\n",
       "      <td>There are 3 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gs://llm_shapes/r0_c1_t0.png</td>\n",
       "      <td>There is 1 circle in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gs://llm_shapes/r0_c6_t0_1.png</td>\n",
       "      <td>There are 6 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gs://llm_shapes/r0_c5_t0_1.png</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gs://llm_shapes/r0_c0_t0_3.png</td>\n",
       "      <td>There are no circles in this image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gs://llm_shapes/r0_c4_t0_4.png</td>\n",
       "      <td>There are 4 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            pic_id                             response  \\\n",
       "17  gs://llm_shapes/r0_c6_t0_2.png    There are 5 circles in the image.   \n",
       "18  gs://llm_shapes/r0_c7_t0_4.png    There are 7 circles in the image.   \n",
       "19  gs://llm_shapes/r0_c7_t0_4.png    There are 7 circles in the image.   \n",
       "20  gs://llm_shapes/r0_c1_t0_1.png      There is 1 circle in the image.   \n",
       "21    gs://llm_shapes/r0_c3_t0.png    There are 3 circles in the image.   \n",
       "22    gs://llm_shapes/r0_c1_t0.png      There is 1 circle in the image.   \n",
       "23  gs://llm_shapes/r0_c6_t0_1.png    There are 6 circles in the image.   \n",
       "24  gs://llm_shapes/r0_c5_t0_1.png    There are 5 circles in the image.   \n",
       "25  gs://llm_shapes/r0_c0_t0_3.png  There are no circles in this image.   \n",
       "26  gs://llm_shapes/r0_c4_t0_4.png    There are 4 circles in the image.   \n",
       "\n",
       "                        notes  \n",
       "17  Differently sized circles  \n",
       "18  Differently sized circles  \n",
       "19  Differently sized circles  \n",
       "20  Differently sized circles  \n",
       "21  Differently sized circles  \n",
       "22  Differently sized circles  \n",
       "23  Differently sized circles  \n",
       "24  Differently sized circles  \n",
       "25  Differently sized circles  \n",
       "26  Differently sized circles  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3ac4c767-774c-4c60-a8db-4cad10192a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectangles_Circles_Triangles.jsonl\n",
      "Triangles.jsonl\n",
      "export-data-Circles_Uniform-2025-08-04T04_10_37.205891Z_image_bounding_box_LLM_Images_Circles_iod-3721021126789300224_data-00001-of-00001.jsonl\n",
      "export-data-Circles_Variety-2025-08-11T10_41_57.250769Z_image_bounding_box_LLM_Images_Circles_Variety_iod-998595152043835392_data-00001-of-00001.jsonl\n",
      "uniform_circles_batch_10.jsonl\n",
      "uniform_circles_batch_20.jsonl\n",
      "uniform_circles_batch_5.jsonl\n"
     ]
    }
   ],
   "source": [
    "list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "422210c4-ddd8-4bf2-9a93-f431776ef4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "triangles = get_image_paths(\"Triangles.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a4c20e5c-b4e3-4334-a095-c18bf0dfd714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_responses(uris,amount=None,dnote=None):\n",
    "    if amount == None:\n",
    "        amount = len(uris) \n",
    "        \n",
    "    subset = random.choices(uris,k=amount)\n",
    "\n",
    "    for uri in subset:\n",
    "        if uri in list(responses[\"pic_id\"]):\n",
    "            continue\n",
    "        image = Part.from_uri(uri, mime_type=\"image/png\") \n",
    "        prompt = \"Count the circles in this image.\"\n",
    "        response = model.generate_content([prompt, image])\n",
    "        response_list.append({\"pic_id\":uri,\"response\":response.text,\"notes\":note})\n",
    "        responses = pd.DataFrame(response_list)\n",
    "        print(uri, \"->\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "494b7ac7-07ac-4615-8d6e-66927f01b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gs://llm_shapes/r0_c0_t4_1.png', 'gs://llm_shapes/r0_c0_t3_3.png', 'gs://llm_shapes/r0_c0_t3_1.png', 'gs://llm_shapes/r0_c0_t6_3.png', 'gs://llm_shapes/r0_c0_t0.png']\n",
      "\n",
      " 20\n"
     ]
    }
   ],
   "source": [
    "print(triangles[:5])\n",
    "print(\"\\n\",len(triangles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b649a6f1-f7bc-4d93-a538-83fd099fb57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://llm_shapes/r0_c0_t5.png -> There are no circles in the image.\n",
      "gs://llm_shapes/r0_c0_t7.png -> There are no circles in the image.\n",
      "gs://llm_shapes/r0_c0_t3_2.png -> There are no circles in the image.\n",
      "gs://llm_shapes/r0_c0_t3_1.png -> There are no circles in the image.\n"
     ]
    }
   ],
   "source": [
    "subset = random.choices(triangles,k=5)\n",
    "\n",
    "for uri in subset:\n",
    "    if uri in list(responses[\"pic_id\"]):\n",
    "        continue\n",
    "    image = Part.from_uri(uri, mime_type=\"image/png\") \n",
    "    prompt = \"Count the circles in this image.\"\n",
    "    response = model.generate_content([prompt, image])\n",
    "    response_list.append({\"pic_id\":uri,\"response\":response.text,\"notes\":\"Triangles\"})\n",
    "    responses = pd.DataFrame(response_list)\n",
    "    print(uri, \"->\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f5f05-9b76-4e16-8276-fe852b20473e",
   "metadata": {},
   "source": [
    "    5/5 correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "300c5438-fe4f-4d7f-ac84-ddab783b20da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://llm_shapes/r0_c0_t0.png -> There are no shapes in this image.\n",
      "gs://llm_shapes/r0_c0_t5.png -> There are 5 shapes in the image, and they are all triangles.\n",
      "gs://llm_shapes/r0_c0_t1_3.png -> There is 1 shape in the image. It is a triangle.\n",
      "gs://llm_shapes/r0_c0_t3_1.png -> There are 5 shapes in the image. They appear to be triangles and quadrilaterals.\n",
      "gs://llm_shapes/r0_c0_t1_2.png -> There is 1 shape in the image. It is a triangle.\n"
     ]
    }
   ],
   "source": [
    "subset = random.choices(triangles,k=5)\n",
    "\n",
    "for uri in subset:\n",
    "    if uri in list(responses[\"pic_id\"]):\n",
    "        continue\n",
    "    image = Part.from_uri(uri, mime_type=\"image/png\") \n",
    "    prompt = \"Count the shapes in this image.\"\n",
    "    response = model.generate_content([prompt, image])\n",
    "    response_list.append({\"pic_id\":uri,\"response\":response.text,\"notes\":\"Triangles\"})\n",
    "    responses = pd.DataFrame(response_list)\n",
    "    print(uri, \"->\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b16d34ec-ab56-4775-8703-d04ed37f316f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectangles.jsonl\n",
      "Rectangles_Circles_Triangles.jsonl\n",
      "Triangles.jsonl\n",
      "export-data-Circles_Uniform-2025-08-04T04_10_37.205891Z_image_bounding_box_LLM_Images_Circles_iod-3721021126789300224_data-00001-of-00001.jsonl\n",
      "export-data-Circles_Variety-2025-08-11T10_41_57.250769Z_image_bounding_box_LLM_Images_Circles_Variety_iod-998595152043835392_data-00001-of-00001.jsonl\n",
      "uniform_circles_batch_10.jsonl\n",
      "uniform_circles_batch_20.jsonl\n",
      "uniform_circles_batch_5.jsonl\n"
     ]
    }
   ],
   "source": [
    "list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b59a2b2-6c3e-4034-aa13-662366874019",
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangles = get_image_paths(\"Rectangles.jsonl\")\n",
    "rect_circ_tri = get_image_paths(\"Rectangles_Circles_Triangles.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ce142b73-9e30-414f-8314-23d3bd9a5f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://llm_shapes/d_r6_c0_t0_2.png -> There are 7 shapes in the image.\n",
      "gs://llm_shapes/d_r2_c0_t0.png -> There are two shapes in the image.\n",
      "gs://llm_shapes/s_r10_c0_t0_5.png -> There are 9 shapes in the image.\n",
      "gs://llm_shapes/s_r4_c0_t0.png -> There are 4 shapes in the image.\n"
     ]
    }
   ],
   "source": [
    "subset = random.choices(rectangles,k=5)\n",
    "\n",
    "for uri in subset:\n",
    "    if uri in list(responses[\"pic_id\"]):\n",
    "        continue\n",
    "    image = Part.from_uri(uri, mime_type=\"image/png\") \n",
    "    prompt = \"Count the shapes in this image.\"\n",
    "    response = model.generate_content([prompt, image])\n",
    "    response_list.append({\"pic_id\":uri,\"response\":response.text,\"notes\":\"Rectangles\"})\n",
    "    responses = pd.DataFrame(response_list)\n",
    "    print(uri, \"->\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "f0faa709-1376-4c52-a254-5a5f5d3505be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://llm_shapes/r7_c3_t0.png -> Here's the shape count and identification for the image:\n",
      "\n",
      "*   **Circles:** 3\n",
      "*   **Rectangles:** 5\n",
      "gs://llm_shapes/r1_c4_t1.png -> Here's the breakdown of the shapes in the image:\n",
      "\n",
      "*   **Circles:** 3\n",
      "*   **Rectangle:** 1\n",
      "*   **Triangle:** 1\n",
      "gs://llm_shapes/r5_c1_t4.png -> Here's the breakdown of shapes in the image:\n",
      "\n",
      "*   **Squares/Rectangles:** There are 5 rectangles (or square) in the image.\n",
      "*   **Triangles:** There are 3 triangles in the image.\n",
      "*   **Circle:** There is 1 circle in the image.\n",
      "gs://llm_shapes/r3_c2_t3.png -> Here's the shape count and identification:\n",
      "\n",
      "*   **Circles:** 2\n",
      "*   **Triangles:** 2\n",
      "*   **Rectangles:** 3\n",
      "gs://llm_shapes/r2_c2_t3.png -> Here's a count and identification of the shapes in the image:\n",
      "\n",
      "*   **Triangles:** There are 3 triangles.\n",
      "*   **Circle:** There are 2 circles.\n",
      "*   **Square:** There is 1 square.\n",
      "*   **Rectangle:** There is 1 rectangle.\n"
     ]
    }
   ],
   "source": [
    "subset = random.choices(rect_circ_tri,k=5)\n",
    "\n",
    "for uri in subset:\n",
    "    if uri in list(responses[\"pic_id\"]):\n",
    "        continue\n",
    "    image = Part.from_uri(uri, mime_type=\"image/png\") \n",
    "    prompt = \"Count and identify the shapes in this image.\"\n",
    "    response = model.generate_content([prompt, image])\n",
    "    response_list.append({\"pic_id\":uri,\"response\":response.text,\"notes\":\"Variety\"})\n",
    "    responses = pd.DataFrame(response_list)\n",
    "    print(uri, \"->\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebb4edd-fdf1-4204-b251-a8ae2eee9b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c19fe6-bcaa-49d9-8a5c-d97d5fc54576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2a0ae9e8-810f-451b-af37-0e36d8bf4438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectangles.jsonl\n",
      "Rectangles_Circles_Triangles.jsonl\n",
      "Triangles.jsonl\n",
      "export-data-Circles_Uniform-2025-08-04T04_10_37.205891Z_image_bounding_box_LLM_Images_Circles_iod-3721021126789300224_data-00001-of-00001.jsonl\n",
      "export-data-Circles_Variety-2025-08-11T10_41_57.250769Z_image_bounding_box_LLM_Images_Circles_Variety_iod-998595152043835392_data-00001-of-00001.jsonl\n",
      "uniform_circles_batch_10.jsonl\n",
      "uniform_circles_batch_20.jsonl\n",
      "uniform_circles_batch_5.jsonl\n"
     ]
    }
   ],
   "source": [
    "list_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c22b9ecf-85f9-41c1-9fd2-f72042ce982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unif_circles = get_image_paths(\"export-data-Circles_Uniform-2025-08-04T04_10_37.205891Z_image_bounding_box_LLM_Images_Circles_iod-3721021126789300224_data-00001-of-00001.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9541ad68-9155-4263-8e0a-c672bbce8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uris = []\n",
    "all_uris.extend(variety_circles)\n",
    "all_uris.extend(rectangles)\n",
    "all_uris.extend(triangles)\n",
    "#all_uris.extend(rect_circ_tri)\n",
    "all_uris.extend(unif_circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "977b16d1-3b1e-4c58-9484-8a67f08f0aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://llm_shapes/r0_c7_t0_6.png',\n",
       " 'gs://llm_shapes/r0_c1_t0.png',\n",
       " 'gs://llm_shapes/r0_c4_t0_4.png',\n",
       " 'gs://llm_shapes/r0_c7_t0.png',\n",
       " 'gs://llm_shapes/r0_c5_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c8_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c3_t0.png',\n",
       " 'gs://llm_shapes/r0_c4_t0.png',\n",
       " 'gs://llm_shapes/r0_c6_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c3_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_4.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c6_t0.png',\n",
       " 'gs://llm_shapes/r0_c4_t0_3.png',\n",
       " 'gs://llm_shapes/r0_c3_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c6_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c0_t0_3.png',\n",
       " 'gs://llm_shapes/r0_c3_t0_3.png',\n",
       " 'gs://llm_shapes/r0_c1_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c4_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c5_t0.png',\n",
       " 'gs://llm_shapes/r0_c2_t0.png',\n",
       " 'gs://llm_shapes/r0_c4_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c8_t0.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_3.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_5.png',\n",
       " 'gs://llm_shapes/r0_c5_t0_2.png',\n",
       " 'gs://llm_shapes/sq_r8_c0_t0_1.png',\n",
       " 'gs://llm_shapes/sq_r6_c0_t0.png',\n",
       " 'gs://llm_shapes/s_r5_c0_t0.png',\n",
       " 'gs://llm_shapes/s_r6_c0_t0_1.png',\n",
       " 'gs://llm_shapes/sq_r8_c0_t0.png',\n",
       " 'gs://llm_shapes/s_r10_c0_t0_1.png',\n",
       " 'gs://llm_shapes/sq_r4_c0_t0_2.png',\n",
       " 'gs://llm_shapes/sq_r4_c0_t0.png',\n",
       " 'gs://llm_shapes/s_r8_c0_t0.png',\n",
       " 'gs://llm_shapes/s_r10_c0_t0_5.png',\n",
       " 'gs://llm_shapes/sq_r7_c0_t0.png',\n",
       " 'gs://llm_shapes/d_r8_c0_t0.png',\n",
       " 'gs://llm_shapes/s_r10_c0_t0_2.png',\n",
       " 'gs://llm_shapes/d_r4_c0_t0_1.png',\n",
       " 'gs://llm_shapes/sq_r1_c0_t0.png',\n",
       " 'gs://llm_shapes/d_r3_c0_t0_1.png',\n",
       " 'gs://llm_shapes/d_r2_c0_t0_1.png',\n",
       " 'gs://llm_shapes/d_r8_c0_t0_1.png',\n",
       " 'gs://llm_shapes/d_r0_c0_t0.png',\n",
       " 'gs://llm_shapes/s_r10_c0_t0_4.png',\n",
       " 'gs://llm_shapes/sq_r7_c0_t0_1.png',\n",
       " 'gs://llm_shapes/s_r2_c0_t0.png',\n",
       " 'gs://llm_shapes/d_r5_c0_t0.png',\n",
       " 'gs://llm_shapes/s_r10_c0_t0_3.png',\n",
       " 'gs://llm_shapes/sq_r3_c0_t0.png',\n",
       " 'gs://llm_shapes/d_r4_c0_t0.png',\n",
       " 'gs://llm_shapes/d_r6_c0_t0_2.png',\n",
       " 'gs://llm_shapes/d_r3_c0_t0_2.png',\n",
       " 'gs://llm_shapes/d_r6_c0_t0_1.png',\n",
       " 'gs://llm_shapes/d_r3_c0_t0.png',\n",
       " 'gs://llm_shapes/d_r7_c0_t0.png',\n",
       " 'gs://llm_shapes/d_r6_c0_t0.png',\n",
       " 'gs://llm_shapes/d_r2_c0_t0.png',\n",
       " 'gs://llm_shapes/s_r8_c0_t0_1.png',\n",
       " 'gs://llm_shapes/s_r4_c0_t0.png',\n",
       " 'gs://llm_shapes/sq_r4_c0_t0_1.png',\n",
       " 'gs://llm_shapes/s_r6_c0_t0.png',\n",
       " 'gs://llm_shapes/s_r10_c0_t0.png',\n",
       " 'gs://llm_shapes/r0_c0_t4_1.png',\n",
       " 'gs://llm_shapes/r0_c0_t3_3.png',\n",
       " 'gs://llm_shapes/r0_c0_t3_1.png',\n",
       " 'gs://llm_shapes/r0_c0_t6_3.png',\n",
       " 'gs://llm_shapes/r0_c0_t0.png',\n",
       " 'gs://llm_shapes/r0_c0_t1.png',\n",
       " 'gs://llm_shapes/r0_c0_t3_5.png',\n",
       " 'gs://llm_shapes/r0_c0_t6.png',\n",
       " 'gs://llm_shapes/r0_c0_t4.png',\n",
       " 'gs://llm_shapes/r0_c0_t4_2.png',\n",
       " 'gs://llm_shapes/r0_c0_t1_1.png',\n",
       " 'gs://llm_shapes/r0_c0_t2.png',\n",
       " 'gs://llm_shapes/r0_c0_t7.png',\n",
       " 'gs://llm_shapes/r0_c0_t1_3.png',\n",
       " 'gs://llm_shapes/r0_c0_t1_2.png',\n",
       " 'gs://llm_shapes/r0_c0_t3_4.png',\n",
       " 'gs://llm_shapes/r0_c0_t5.png',\n",
       " 'gs://llm_shapes/r0_c0_t8.png',\n",
       " 'gs://llm_shapes/r0_c0_t5_1.png',\n",
       " 'gs://llm_shapes/r0_c0_t3_2.png',\n",
       " 'gs://llm_shapes/r0_c5_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_5.png',\n",
       " 'gs://llm_shapes/r0_c6_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_6.png',\n",
       " 'gs://llm_shapes/r0_c1_t0_6.png',\n",
       " 'gs://llm_shapes/r0_c1_t0.png',\n",
       " 'gs://llm_shapes/r0_c4_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c7_t0.png',\n",
       " 'gs://llm_shapes/r0_c6_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c2_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c1_t0_4.png',\n",
       " 'gs://llm_shapes/r0_c8_t0_3.png',\n",
       " 'gs://llm_shapes/r0_c8_t0.png',\n",
       " 'gs://llm_shapes/r0_c0_t0.png',\n",
       " 'gs://llm_shapes/r0_c4_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c8_t0_4.png',\n",
       " 'gs://llm_shapes/r0_c5_t0.png',\n",
       " 'gs://llm_shapes/r0_c2_t0.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_3.png',\n",
       " 'gs://llm_shapes/r0_c2_t0_3.png',\n",
       " 'gs://llm_shapes/r0_c8_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c1_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c4_t0_5.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c1_t0_3.png',\n",
       " 'gs://llm_shapes/r0_c4_t0.png',\n",
       " 'gs://llm_shapes/r0_c6_t0_4.png',\n",
       " 'gs://llm_shapes/r0_c7_t0_4.png',\n",
       " 'gs://llm_shapes/r0_c1_t0_5.png',\n",
       " 'gs://llm_shapes/r0_c3_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c2_t0_4.png',\n",
       " 'gs://llm_shapes/r0_c4_t0_3.png',\n",
       " 'gs://llm_shapes/r0_c3_t0.png',\n",
       " 'gs://llm_shapes/r0_c4_t0_4.png',\n",
       " 'gs://llm_shapes/r0_c6_t0_3.png',\n",
       " 'gs://llm_shapes/r0_c2_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c3_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c8_t0_1.png',\n",
       " 'gs://llm_shapes/r0_c2_t0_5.png',\n",
       " 'gs://llm_shapes/r0_c1_t0_2.png',\n",
       " 'gs://llm_shapes/r0_c6_t0.png']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b7c1ea73-2c50-4ccf-822f-df551ba7f249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://llm_shapes/export-data-Circles_Uniform-2025-08-04T04:10:37.205891Z/image_bounding_box/LLM_Images_Circles_iod-3721021126789300224'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_bucket_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f7a5f1-2772-491d-97b8-13e1301850fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs://llm_shapes/export-data-Rectangles_Circles_Triangles-2025-08-11T10:55:32.804570Z/image_bounding_box/Rectangles_Circles_Triangles_iod-7252969134554611712/data-00001-of-00001.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "086df8f2-f465-4e41-bd95-a9acfddf3d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zainabsiddiqui/Downloads/Data_Problems/LLM_Project'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "8f6bc6d9-e2d2-47c3-9825-22251b9f48d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Gemini tuning file to /Users/zainabsiddiqui/Downloads/Data_Problems/LLM_Project/Data/annotation_sets/clean_train.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_path = \"/Users/zainabsiddiqui/Downloads/Data_Problems/LLM_Project/Data/annotation_sets/train.jsonl\"   # your Vertex export file\n",
    "output_path = \"/Users/zainabsiddiqui/Downloads/Data_Problems/LLM_Project/Data/annotation_sets/clean_train.jsonl\" # multimodal fine-tune file\n",
    "\n",
    "with open(input_path, \"r\") as infile, open(output_path, \"w\") as outfile:\n",
    "    for line in infile:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        image_uri = data[\"imageGcsUri\"]\n",
    "        bboxes = data[\"boundingBoxAnnotations\"]\n",
    "\n",
    "        # Put bounding boxes in the model's \"answer\" text\n",
    "        answer_text = json.dumps([\n",
    "            {\n",
    "                \"label\": ann[\"displayName\"],\n",
    "                \"xMin\": ann[\"xMin\"],\n",
    "                \"xMax\": ann[\"xMax\"],\n",
    "                \"yMin\": ann[\"yMin\"],\n",
    "                \"yMax\": ann[\"yMax\"]\n",
    "            }\n",
    "            for ann in bboxes\n",
    "        ])\n",
    "\n",
    "        row = {\n",
    "            \"contents\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"parts\": [\n",
    "                        {\n",
    "                            \"file_data\": {\n",
    "                                \"file_uri\": image_uri,\n",
    "                                \"mime_type\": \"image/png\"\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"text\": \"List all circles and their bounding boxes in JSON.\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"model\",\n",
    "                    \"parts\": [\n",
    "                        {\"text\": answer_text}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        outfile.write(json.dumps(row) + \"\\n\")\n",
    "\n",
    "print(f\"Saved Gemini tuning file to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e176ff08-444a-400e-a033-f325bdd29eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SupervisedTuningJob\n",
      "SupervisedTuningJob created. Resource name: projects/665016930796/locations/us-central1/tuningJobs/869096132813258752\n",
      "To use this SupervisedTuningJob in another session:\n",
      "tuning_job = sft.SupervisedTuningJob('projects/665016930796/locations/us-central1/tuningJobs/869096132813258752')\n",
      "View Tuning Job:\n",
      "https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/869096132813258752?project=665016930796\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-be9d1680-8148-44bc-8732-c811c8f50bc7\" href=\"#view-view-vertex-resource-be9d1680-8148-44bc-8732-c811c8f50bc7\">\n",
       "          <span class=\"material-icons view-vertex-icon\">tune</span>\n",
       "          <span>View Tuning Job</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-be9d1680-8148-44bc-8732-c811c8f50bc7');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/869096132813258752?project=665016930796');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/generative/language/locations/us-central1/tuning/tuningJob/869096132813258752?project=665016930796', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-fbfe6ded-4320-4d4b-b464-80ca5ff23254\" href=\"#view-view-vertex-resource-fbfe6ded-4320-4d4b-b464-80ca5ff23254\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-fbfe6ded-4320-4d4b-b464-80ca5ff23254');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/tuning-experiment-20250811053537482099/runs?project=mystic-creek-467304-u7');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/tuning-experiment-20250811053537482099/runs?project=mystic-creek-467304-u7', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/665016930796/locations/us-central1/models/938845491167232000@1\n",
      "projects/665016930796/locations/us-central1/endpoints/3315004468000456704\n",
      "<google.cloud.aiplatform.metadata.experiment_resources.Experiment object at 0x17ddf7dd0>\n"
     ]
    }
   ],
   "source": [
    "# TODO(developer): Update and un-comment below line\n",
    "PROJECT_ID = project_id\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "\n",
    "\n",
    "\n",
    "sft_tuning_job = sft.train(\n",
    "    source_model=\"gemini-2.0-flash-001\",\n",
    "    # 1.5 and 2.0 models use the same JSONL format\n",
    "    train_dataset= \"gs://llm_shapes/export-data-Rectangles_Circles_Triangles-2025-08-11T10:55:32.804570Z/image_bounding_box/Rectangles_Circles_Triangles_iod-7252969134554611712/clean_train.jsonl\",\n",
    "    #\"gs://llm_shapes/export-data-Rectangles_Circles_Triangles-2025-08-11T10:55:32.804570Z/image_bounding_box/Rectangles_Circles_Triangles_iod-7252969134554611712/data-00001-of-00001.jsonl\"\n",
    ")\n",
    "\n",
    "# Polling for job completion\n",
    "while not sft_tuning_job.has_ended:\n",
    "    time.sleep(60)\n",
    "    sft_tuning_job.refresh()\n",
    "\n",
    "print(sft_tuning_job.tuned_model_name)\n",
    "print(sft_tuning_job.tuned_model_endpoint_name)\n",
    "print(sft_tuning_job.experiment)\n",
    "# Example response:\n",
    "# projects/123456789012/locations/us-central1/models/1234567890@1\n",
    "# projects/123456789012/locations/us-central1/endpoints/123456789012345\n",
    "# <google.cloud.aiplatform.metadata.experiment_resources.Experiment object at 0x7b5b4ae07af0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "826443a0-6352-49e0-8a44-ac9841ff2c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"3315004468000456704\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "789985d6-e8d8-4a6f-9e80-d4dbef79f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_name = \"projects/665016930796/locations/us-central1/models/938845491167232000@1\"\n",
    "\n",
    "#model_resource_name = \"projects/your-gcp-project-id/locations/your-region/models/your-model-id\"\n",
    "tuned_model = aiplatform.Model(model_name=tuned_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac046b7-1f0e-4937-ad12-0837f9ae80f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1abf62ad-2dd5-43a3-ad85-ea173943d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "138920a3-e5dd-482d-ace8-b96b840f9103",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53a2d69c-b99e-4fb3-acd4-af771807452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Model in module google.cloud.aiplatform.models:\n",
      "\n",
      "class Model(google.cloud.aiplatform.base.VertexAiResourceNounWithFutureManager, google.cloud.aiplatform.base.PreviewMixin)\n",
      " |  Model(model_name: str, project: Optional[str] = None, location: Optional[str] = None, credentials: Optional[google.auth.credentials.Credentials] = None, version: Optional[str] = None)\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      Model\n",
      " |      google.cloud.aiplatform.base.VertexAiResourceNounWithFutureManager\n",
      " |      google.cloud.aiplatform.base._VertexAiResourceNounPlus\n",
      " |      google.cloud.aiplatform.base.VertexAiResourceNoun\n",
      " |      google.cloud.aiplatform.base.FutureManager\n",
      " |      google.cloud.aiplatform.base.PreviewMixin\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, model_name: str, project: Optional[str] = None, location: Optional[str] = None, credentials: Optional[google.auth.credentials.Credentials] = None, version: Optional[str] = None)\n",
      " |      Retrieves the model resource and instantiates its representation.\n",
      " |\n",
      " |      Args:\n",
      " |          model_name (str):\n",
      " |              Required. A fully-qualified model resource name or model ID.\n",
      " |              Example: \"projects/123/locations/us-central1/models/456\" or\n",
      " |              \"456\" when project and location are initialized or passed.\n",
      " |              May optionally contain a version ID or version alias in\n",
      " |              {model_name}@{version} form. See version arg.\n",
      " |          project (str):\n",
      " |              Optional project to retrieve model from. If not set, project\n",
      " |              set in aiplatform.init will be used.\n",
      " |          location (str):\n",
      " |              Optional location to retrieve model from. If not set, location\n",
      " |              set in aiplatform.init will be used.\n",
      " |          credentials: Optional[auth_credentials.Credentials]=None,\n",
      " |              Custom credentials to use to upload this model. If not set,\n",
      " |              credentials set in aiplatform.init will be used.\n",
      " |          version (str):\n",
      " |              Optional. Version ID or version alias.\n",
      " |              When set, the specified model version will be targeted\n",
      " |              unless overridden in method calls.\n",
      " |              When not set, the model with the \"default\" alias will\n",
      " |              be targeted unless overridden in method calls.\n",
      " |              No behavior change if only one version of a model exists.\n",
      " |      Raises:\n",
      " |          ValueError: If `version` is passed alongside a model_name referencing a different version.\n",
      " |\n",
      " |  batch_predict(self, job_display_name: Optional[str] = None, gcs_source: Union[str, Sequence[str], NoneType] = None, bigquery_source: Optional[str] = None, instances_format: str = 'jsonl', gcs_destination_prefix: Optional[str] = None, bigquery_destination_prefix: Optional[str] = None, predictions_format: str = 'jsonl', model_parameters: Optional[Dict] = None, machine_type: Optional[str] = None, accelerator_type: Optional[str] = None, accelerator_count: Optional[int] = None, starting_replica_count: Optional[int] = None, max_replica_count: Optional[int] = None, generate_explanation: Optional[bool] = False, explanation_metadata: Optional[google.cloud.aiplatform_v1.types.explanation_metadata.ExplanationMetadata] = None, explanation_parameters: Optional[google.cloud.aiplatform_v1.types.explanation.ExplanationParameters] = None, labels: Optional[Dict[str, str]] = None, credentials: Optional[google.auth.credentials.Credentials] = None, encryption_spec_key_name: Optional[str] = None, sync: bool = True, create_request_timeout: Optional[float] = None, batch_size: Optional[int] = None, service_account: Optional[str] = None) -> google.cloud.aiplatform.jobs.BatchPredictionJob\n",
      " |      Creates a batch prediction job using this Model and outputs\n",
      " |      prediction results to the provided destination prefix in the specified\n",
      " |      `predictions_format`. One source and one destination prefix are\n",
      " |      required.\n",
      " |\n",
      " |      Example usage:\n",
      " |          my_model.batch_predict(\n",
      " |              job_display_name=\"prediction-123\",\n",
      " |              gcs_source=\"gs://example-bucket/instances.csv\",\n",
      " |              instances_format=\"csv\",\n",
      " |              bigquery_destination_prefix=\"projectId.bqDatasetId.bqTableId\"\n",
      " |          )\n",
      " |\n",
      " |      Args:\n",
      " |          job_display_name (str):\n",
      " |              Optional. The user-defined name of the BatchPredictionJob.\n",
      " |              The name can be up to 128 characters long and can be consist\n",
      " |              of any UTF-8 characters.\n",
      " |          gcs_source: Optional[Sequence[str]] = None\n",
      " |              Google Cloud Storage URI(-s) to your instances to run\n",
      " |              batch prediction on. They must match `instances_format`.\n",
      " |          bigquery_source: Optional[str] = None\n",
      " |              BigQuery URI to a table, up to 2000 characters long. For example:\n",
      " |              `bq://projectId.bqDatasetId.bqTableId`\n",
      " |          instances_format: str = \"jsonl\"\n",
      " |              The format in which instances are provided. Must be one\n",
      " |              of the formats listed in `Model.supported_input_storage_formats`.\n",
      " |              Default is \"jsonl\" when using `gcs_source`. If a `bigquery_source`\n",
      " |              is provided, this is overridden to \"bigquery\".\n",
      " |          gcs_destination_prefix: Optional[str] = None\n",
      " |              The Google Cloud Storage location of the directory where the\n",
      " |              output is to be written to. In the given directory a new\n",
      " |              directory is created. Its name is\n",
      " |              ``prediction-<model-display-name>-<job-create-time>``, where\n",
      " |              timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format.\n",
      " |              Inside of it files ``predictions_0001.<extension>``,\n",
      " |              ``predictions_0002.<extension>``, ...,\n",
      " |              ``predictions_N.<extension>`` are created where\n",
      " |              ``<extension>`` depends on chosen ``predictions_format``,\n",
      " |              and N may equal 0001 and depends on the total number of\n",
      " |              successfully predicted instances. If the Model has both\n",
      " |              ``instance`` and ``prediction`` schemata defined then each such\n",
      " |              file contains predictions as per the ``predictions_format``.\n",
      " |              If prediction for any instance failed (partially or\n",
      " |              completely), then an additional ``errors_0001.<extension>``,\n",
      " |              ``errors_0002.<extension>``,..., ``errors_N.<extension>``\n",
      " |              files are created (N depends on total number of failed\n",
      " |              predictions). These files contain the failed instances, as\n",
      " |              per their schema, followed by an additional ``error`` field\n",
      " |              which as value has ```google.rpc.Status`` <Status>`__\n",
      " |              containing only ``code`` and ``message`` fields.\n",
      " |          bigquery_destination_prefix: Optional[str] = None\n",
      " |              The BigQuery URI to a project or table, up to 2000 characters long.\n",
      " |              When only the project is specified, the Dataset and Table is created.\n",
      " |              When the full table reference is specified, the Dataset must exist and\n",
      " |              table must not exist. Accepted forms: ``bq://projectId`` or\n",
      " |              ``bq://projectId.bqDatasetId``. If no Dataset is specified,\n",
      " |              a new one is created with the name\n",
      " |              ``prediction_<model-display-name>_<job-create-time>``\n",
      " |              where the table name is made BigQuery-dataset-name compatible\n",
      " |              (for example, most special characters become underscores), and\n",
      " |              timestamp is in YYYY_MM_DDThh_mm_ss_sssZ \"based on ISO-8601\"\n",
      " |              format. In the dataset two tables will be created, ``predictions``,\n",
      " |              and ``errors``. If the Model has both ``instance`` and\n",
      " |              ``prediction`` schemata defined then the tables have columns as\n",
      " |              follows: The ``predictions`` table contains instances for which\n",
      " |              the prediction succeeded, it has columns as per a concatenation\n",
      " |              of the Model's instance and prediction schemata. The ``errors``\n",
      " |              table contains rows for which the prediction has failed, it has\n",
      " |              instance columns, as per the instance schema, followed by a single\n",
      " |              \"errors\" column, which as values has ```google.rpc.Status`` <Status>`__\n",
      " |              represented as a STRUCT, and containing only ``code`` and ``message``.\n",
      " |          predictions_format: str = \"jsonl\"\n",
      " |              Required. The format in which Vertex AI outputs the\n",
      " |              predictions, must be one of the formats specified in\n",
      " |              `Model.supported_output_storage_formats`.\n",
      " |              Default is \"jsonl\" when using `gcs_destination_prefix`. If a\n",
      " |              `bigquery_destination_prefix` is provided, this is overridden to\n",
      " |              \"bigquery\".\n",
      " |          model_parameters: Optional[Dict] = None\n",
      " |              Optional. The parameters that govern the predictions. The schema of\n",
      " |              the parameters may be specified via the Model's `parameters_schema_uri`.\n",
      " |          machine_type: Optional[str] = None\n",
      " |              Optional. The type of machine for running batch prediction on\n",
      " |              dedicated resources. Not specifying machine type will result in\n",
      " |              batch prediction job being run with automatic resources.\n",
      " |          accelerator_type: Optional[str] = None\n",
      " |              Optional. The type of accelerator(s) that may be attached\n",
      " |              to the machine as per `accelerator_count`. Only used if\n",
      " |              `machine_type` is set.\n",
      " |          accelerator_count: Optional[int] = None\n",
      " |              Optional. The number of accelerators to attach to the\n",
      " |              `machine_type`. Only used if `machine_type` is set.\n",
      " |          starting_replica_count: Optional[int] = None\n",
      " |              The number of machine replicas used at the start of the batch\n",
      " |              operation. If not set, Vertex AI decides starting number, not\n",
      " |              greater than `max_replica_count`. Only used if `machine_type` is\n",
      " |              set.\n",
      " |          max_replica_count: Optional[int] = None\n",
      " |              The maximum number of machine replicas the batch operation may\n",
      " |              be scaled to. Only used if `machine_type` is set.\n",
      " |              Default is 10.\n",
      " |          generate_explanation (bool):\n",
      " |              Optional. Generate explanation along with the batch prediction\n",
      " |              results. This will cause the batch prediction output to include\n",
      " |              explanations based on the `prediction_format`:\n",
      " |                  - `bigquery`: output includes a column named `explanation`. The value\n",
      " |                      is a struct that conforms to the [aiplatform.gapic.Explanation] object.\n",
      " |                  - `jsonl`: The JSON objects on each line include an additional entry\n",
      " |                      keyed `explanation`. The value of the entry is a JSON object that\n",
      " |                      conforms to the [aiplatform.gapic.Explanation] object.\n",
      " |                  - `csv`: Generating explanations for CSV format is not supported.\n",
      " |          explanation_metadata (aiplatform.explain.ExplanationMetadata):\n",
      " |              Optional. Explanation metadata configuration for this BatchPredictionJob.\n",
      " |              Can be specified only if `generate_explanation` is set to `True`.\n",
      " |\n",
      " |              This value overrides the value of `Model.explanation_metadata`.\n",
      " |              All fields of `explanation_metadata` are optional in the request. If\n",
      " |              a field of the `explanation_metadata` object is not populated, the\n",
      " |              corresponding field of the `Model.explanation_metadata` object is inherited.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1igh60kt>`\n",
      " |          explanation_parameters (aiplatform.explain.ExplanationParameters):\n",
      " |              Optional. Parameters to configure explaining for Model's predictions.\n",
      " |              Can be specified only if `generate_explanation` is set to `True`.\n",
      " |\n",
      " |              This value overrides the value of `Model.explanation_parameters`.\n",
      " |              All fields of `explanation_parameters` are optional in the request. If\n",
      " |              a field of the `explanation_parameters` object is not populated, the\n",
      " |              corresponding field of the `Model.explanation_parameters` object is inherited.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1an4zake>`\n",
      " |          labels: Optional[Dict[str, str]] = None\n",
      " |              Optional. The labels with user-defined metadata to organize your\n",
      " |              BatchPredictionJobs. Label keys and values can be no longer than\n",
      " |              64 characters (Unicode codepoints), can only contain lowercase\n",
      " |              letters, numeric characters, underscores and dashes.\n",
      " |              International characters are allowed. See https://goo.gl/xmQnxf\n",
      " |              for more information and examples of labels.\n",
      " |          credentials: Optional[auth_credentials.Credentials] = None\n",
      " |              Optional. Custom credentials to use to create this batch prediction\n",
      " |              job. Overrides credentials set in aiplatform.init.\n",
      " |          encryption_spec_key_name (Optional[str]):\n",
      " |              Optional. The Cloud KMS resource identifier of the customer\n",
      " |              managed encryption key used to protect the model. Has the\n",
      " |              form:\n",
      " |              ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.\n",
      " |              The key needs to be in the same region as where the compute\n",
      " |              resource is created.\n",
      " |\n",
      " |              If set, this Model and all sub-resources of this Model will be secured by this key.\n",
      " |\n",
      " |              Overrides encryption_spec_key_name set in aiplatform.init.\n",
      " |          create_request_timeout (float):\n",
      " |              Optional. The timeout for the create request in seconds.\n",
      " |          batch_size (int):\n",
      " |              Optional. The number of the records (e.g. instances) of the operation given in each batch\n",
      " |              to a machine replica. Machine type, and size of a single record should be considered\n",
      " |              when setting this parameter, higher value speeds up the batch operation's execution,\n",
      " |              but too high value will result in a whole batch not fitting in a machine's memory,\n",
      " |              and the whole operation will fail.\n",
      " |              The default value is 64.\n",
      " |          service_account (str):\n",
      " |              Optional. Specifies the service account for workload run-as account.\n",
      " |              Users submitting jobs must have act-as permission on this run-as account.\n",
      " |\n",
      " |      Returns:\n",
      " |          job (jobs.BatchPredictionJob):\n",
      " |              Instantiated representation of the created batch prediction job.\n",
      " |\n",
      " |  copy(self, destination_location: str, destination_model_id: Optional[str] = None, destination_parent_model: Optional[str] = None, encryption_spec_key_name: Optional[str] = None, copy_request_timeout: Optional[float] = None) -> 'Model'\n",
      " |      Copys a model and returns a Model representing the copied Model\n",
      " |      resource. This method is a blocking call.\n",
      " |\n",
      " |      Example usage:\n",
      " |          copied_model = my_model.copy(\n",
      " |              destination_location=\"us-central1\"\n",
      " |          )\n",
      " |\n",
      " |      Args:\n",
      " |          destination_location (str):\n",
      " |              The destination location to copy the model to.\n",
      " |          destination_model_id (str):\n",
      " |              Optional. The ID to use for the copied Model, which will\n",
      " |              become the final component of the model resource name.\n",
      " |              This value may be up to 63 characters, and valid characters\n",
      " |              are `[a-z0-9_-]`. The first character cannot be a number or hyphen.\n",
      " |\n",
      " |              Only set this field when copying as a new model. If this field is not set,\n",
      " |              a numeric model id will be generated.\n",
      " |          destination_parent_model (str):\n",
      " |              Optional. The resource name or model ID of an existing model that the\n",
      " |              newly-copied model will be a version of.\n",
      " |\n",
      " |              Only set this field when copying as a new version of an existing model.\n",
      " |          encryption_spec_key_name (Optional[str]):\n",
      " |              Optional. The Cloud KMS resource identifier of the customer\n",
      " |              managed encryption key used to protect the model. Has the\n",
      " |              form:\n",
      " |              ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.\n",
      " |              The key needs to be in the same region as where the compute\n",
      " |              resource is created.\n",
      " |\n",
      " |              If set, this Model and all sub-resources of this Model will be secured by this key.\n",
      " |\n",
      " |              Overrides encryption_spec_key_name set in aiplatform.init.\n",
      " |          copy_request_timeout (float):\n",
      " |              Optional. The timeout for the copy request in seconds.\n",
      " |\n",
      " |      Returns:\n",
      " |          model (aiplatform.Model):\n",
      " |              Instantiated representation of the copied model resource.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValueError: If both `destination_model_id` and `destination_parent_model` are set.\n",
      " |\n",
      " |  deploy(self, endpoint: Union[ForwardRef('Endpoint'), ForwardRef('PrivateEndpoint'), NoneType] = None, deployed_model_display_name: Optional[str] = None, traffic_percentage: Optional[int] = 0, traffic_split: Optional[Dict[str, int]] = None, machine_type: Optional[str] = None, min_replica_count: int = 1, max_replica_count: int = 1, accelerator_type: Optional[str] = None, accelerator_count: Optional[int] = None, tpu_topology: Optional[str] = None, service_account: Optional[str] = None, explanation_metadata: Optional[google.cloud.aiplatform_v1.types.explanation_metadata.ExplanationMetadata] = None, explanation_parameters: Optional[google.cloud.aiplatform_v1.types.explanation.ExplanationParameters] = None, metadata: Optional[Sequence[Tuple[str, str]]] = (), encryption_spec_key_name: Optional[str] = None, network: Optional[str] = None, sync=True, deploy_request_timeout: Optional[float] = None, autoscaling_target_cpu_utilization: Optional[int] = None, autoscaling_target_accelerator_duty_cycle: Optional[int] = None, autoscaling_target_request_count_per_minute: Optional[int] = None, enable_access_logging=False, disable_container_logging: bool = False, private_service_connect_config: Optional[google.cloud.aiplatform.models.PrivateEndpoint.PrivateServiceConnectConfig] = None, deployment_resource_pool: Optional[google.cloud.aiplatform.models.DeploymentResourcePool] = None, reservation_affinity_type: Optional[str] = None, reservation_affinity_key: Optional[str] = None, reservation_affinity_values: Optional[List[str]] = None, spot: bool = False, fast_tryout_enabled: bool = False, system_labels: Optional[Dict[str, str]] = None, required_replica_count: Optional[int] = 0) -> Union[google.cloud.aiplatform.models.Endpoint, google.cloud.aiplatform.models.PrivateEndpoint]\n",
      " |      Deploys model to endpoint. Endpoint will be created if unspecified.\n",
      " |\n",
      " |      Args:\n",
      " |          endpoint (Union[Endpoint, PrivateEndpoint]):\n",
      " |              Optional. Public or private Endpoint to deploy model to. If not specified,\n",
      " |              endpoint display name will be model display name+'_endpoint'.\n",
      " |          deployed_model_display_name (str):\n",
      " |              Optional. The display name of the DeployedModel. If not provided\n",
      " |              upon creation, the Model's display_name is used.\n",
      " |          traffic_percentage (int):\n",
      " |              Optional. Desired traffic to newly deployed model. Defaults to\n",
      " |              0 if there are pre-existing deployed models. Defaults to 100 if\n",
      " |              there are no pre-existing deployed models. Negative values should\n",
      " |              not be provided. Traffic of previously deployed models at the endpoint\n",
      " |              will be scaled down to accommodate new deployed model's traffic.\n",
      " |              Should not be provided if traffic_split is provided.\n",
      " |          traffic_split (Dict[str, int]):\n",
      " |              Optional. A map from a DeployedModel's ID to the percentage of\n",
      " |              this Endpoint's traffic that should be forwarded to that DeployedModel.\n",
      " |              If a DeployedModel's ID is not listed in this map, then it receives\n",
      " |              no traffic. The traffic percentage values must add up to 100, or\n",
      " |              map must be empty if the Endpoint is to not accept any traffic at\n",
      " |              the moment. Key for model being deployed is \"0\". Should not be\n",
      " |              provided if traffic_percentage is provided.\n",
      " |          machine_type (str):\n",
      " |              Optional. The type of machine. Not specifying machine type will\n",
      " |              result in model to be deployed with automatic resources.\n",
      " |          min_replica_count (int):\n",
      " |              Optional. The minimum number of machine replicas this deployed\n",
      " |              model will be always deployed on. If traffic against it increases,\n",
      " |              it may dynamically be deployed onto more replicas, and as traffic\n",
      " |              decreases, some of these extra replicas may be freed.\n",
      " |          max_replica_count (int):\n",
      " |              Optional. The maximum number of replicas this deployed model may\n",
      " |              be deployed on when the traffic against it increases. If requested\n",
      " |              value is too large, the deployment will error, but if deployment\n",
      " |              succeeds then the ability to scale the model to that many replicas\n",
      " |              is guaranteed (barring service outages). If traffic against the\n",
      " |              deployed model increases beyond what its replicas at maximum may\n",
      " |              handle, a portion of the traffic will be dropped. If this value\n",
      " |              is not provided, the smaller value of min_replica_count or 1 will\n",
      " |              be used.\n",
      " |          accelerator_type (str):\n",
      " |              Optional. Hardware accelerator type. Must also set accelerator_count if used.\n",
      " |              One of ACCELERATOR_TYPE_UNSPECIFIED, NVIDIA_TESLA_K80, NVIDIA_TESLA_P100,\n",
      " |              NVIDIA_TESLA_V100, NVIDIA_TESLA_P4, NVIDIA_TESLA_T4\n",
      " |          accelerator_count (int):\n",
      " |              Optional. The number of accelerators to attach to a worker replica.\n",
      " |          tpu_topology (str):\n",
      " |              Optional. The TPU topology to use for the DeployedModel.\n",
      " |              Requireid for CloudTPU multihost deployments.\n",
      " |          service_account (str):\n",
      " |              The service account that the DeployedModel's container runs as. Specify the\n",
      " |              email address of the service account. If this service account is not\n",
      " |              specified, the container runs as a service account that doesn't have access\n",
      " |              to the resource project.\n",
      " |              Users deploying the Model must have the `iam.serviceAccounts.actAs`\n",
      " |              permission on this service account.\n",
      " |          explanation_metadata (aiplatform.explain.ExplanationMetadata):\n",
      " |              Optional. Metadata describing the Model's input and output for explanation.\n",
      " |              `explanation_metadata` is optional while `explanation_parameters` must be\n",
      " |              specified when used.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1igh60kt>`\n",
      " |          explanation_parameters (aiplatform.explain.ExplanationParameters):\n",
      " |              Optional. Parameters to configure explaining for Model's predictions.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1an4zake>`\n",
      " |          metadata (Sequence[Tuple[str, str]]):\n",
      " |              Optional. Strings which should be sent along with the request as\n",
      " |              metadata.\n",
      " |          encryption_spec_key_name (Optional[str]):\n",
      " |              Optional. The Cloud KMS resource identifier of the customer\n",
      " |              managed encryption key used to protect the model. Has the\n",
      " |              form:\n",
      " |              ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.\n",
      " |              The key needs to be in the same region as where the compute\n",
      " |              resource is created.\n",
      " |\n",
      " |              If set, this Endpoint and all sub-resources of this Endpoint will be secured by this key.\n",
      " |\n",
      " |              Overrides encryption_spec_key_name set in aiplatform.init.\n",
      " |          network (str):\n",
      " |              Optional. The full name of the Compute Engine network to which\n",
      " |              the Endpoint, if created, will be peered to. E.g. \"projects/12345/global/networks/myVPC\"\n",
      " |              Private services access must already be configured for the network.\n",
      " |              If set or aiplatform.init(network=...) has been set, a PrivateEndpoint will be created.\n",
      " |              If left unspecified, an Endpoint will be created. Read more about PrivateEndpoints\n",
      " |              [in the documentation](https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints).\n",
      " |              Cannot be set together with private_service_connect_config.\n",
      " |          sync (bool):\n",
      " |              Whether to execute this method synchronously. If False, this method\n",
      " |              will be executed in concurrent Future and any downstream object will\n",
      " |              be immediately returned and synced when the Future has completed.\n",
      " |          deploy_request_timeout (float):\n",
      " |              Optional. The timeout for the deploy request in seconds.\n",
      " |          autoscaling_target_cpu_utilization (int):\n",
      " |              Optional. Target CPU Utilization to use for Autoscaling Replicas.\n",
      " |              A default value of 60 will be used if not specified.\n",
      " |          autoscaling_target_accelerator_duty_cycle (int):\n",
      " |              Optional. Target Accelerator Duty Cycle.\n",
      " |              Must also set accelerator_type and accelerator_count if specified.\n",
      " |              A default value of 60 will be used if not specified.\n",
      " |          autoscaling_target_request_count_per_minute (int):\n",
      " |              Optional. The target number of requests per minute for autoscaling.\n",
      " |              If set, the model will be scaled based on the number of requests it receives.\n",
      " |          enable_access_logging (bool):\n",
      " |              Whether to enable endpoint access logging. Defaults to False.\n",
      " |          disable_container_logging (bool):\n",
      " |              If True, container logs from the deployed model will not be\n",
      " |              written to Cloud Logging. Defaults to False.\n",
      " |          private_service_connect_config (PrivateEndpoint.PrivateServiceConnectConfig):\n",
      " |              If true, the endpoint can be accessible via [Private Service Connect](https://cloud.google.com/vpc/docs/private-service-connect).\n",
      " |              Cannot be set together with network.\n",
      " |          deployment_resource_pool (DeploymentResourcePool):\n",
      " |              Resource pool where the model will be deployed. All models that\n",
      " |              are deployed to the same DeploymentResourcePool will be hosted in\n",
      " |              a shared model server. If provided, will override replica count\n",
      " |              arguments.\n",
      " |          reservation_affinity_type (str):\n",
      " |              Optional. The type of reservation affinity.\n",
      " |              One of NO_RESERVATION, ANY_RESERVATION, SPECIFIC_RESERVATION,\n",
      " |              SPECIFIC_THEN_ANY_RESERVATION, SPECIFIC_THEN_NO_RESERVATION\n",
      " |          reservation_affinity_key (str):\n",
      " |              Optional. Corresponds to the label key of a reservation resource.\n",
      " |              To target a SPECIFIC_RESERVATION by name, use `compute.googleapis.com/reservation-name` as the key\n",
      " |              and specify the name of your reservation as its value.\n",
      " |          reservation_affinity_values (List[str]):\n",
      " |              Optional. Corresponds to the label values of a reservation resource.\n",
      " |              This must be the full resource name of the reservation.\n",
      " |              Format: 'projects/{project_id_or_number}/zones/{zone}/reservations/{reservation_name}'\n",
      " |          spot (bool):\n",
      " |              Optional. Whether to schedule the deployment workload on spot VMs.\n",
      " |          fast_tryout_enabled (bool):\n",
      " |            Optional. Defaults to False.\n",
      " |            If True, model will be deployed using faster deployment path.\n",
      " |            Useful for quick experiments. Not for production workloads. Only\n",
      " |            available for most popular models with certain machine types.\n",
      " |          system_labels (Dict[str, str]):\n",
      " |              Optional. System labels to apply to Model Garden deployments.\n",
      " |              System labels are managed by Google for internal use only.\n",
      " |          required_replica_count (int):\n",
      " |              Optional. Number of required available replicas for the\n",
      " |              deployment to succeed. This field is only needed when partial\n",
      " |              model deployment/mutation is desired, with a value greater than\n",
      " |              or equal to 1 and fewer than or equal to min_replica_count. If\n",
      " |              set, the model deploy/mutate operation will succeed once\n",
      " |              available_replica_count reaches required_replica_count, and the\n",
      " |              rest of the replicas will be retried.\n",
      " |\n",
      " |      Returns:\n",
      " |          endpoint (Union[Endpoint, PrivateEndpoint]):\n",
      " |              Endpoint with the deployed model.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValueError: If `traffic_split` is set for PrivateEndpoint.\n",
      " |\n",
      " |  evaluate(self, prediction_type: str, target_field_name: str, gcs_source_uris: Optional[List[str]] = None, bigquery_source_uri: Optional[str] = None, bigquery_destination_output_uri: Optional[str] = None, class_labels: Optional[List[str]] = None, prediction_label_column: Optional[str] = None, prediction_score_column: Optional[str] = None, staging_bucket: Optional[str] = None, service_account: Optional[str] = None, generate_feature_attributions: bool = False, evaluation_pipeline_display_name: Optional[str] = None, evaluation_metrics_display_name: Optional[str] = None, network: Optional[str] = None, encryption_spec_key_name: Optional[str] = None, experiment: Union[str, ForwardRef('aiplatform.Experiment'), NoneType] = None, enable_caching: Optional[bool] = None) -> 'model_evaluation._ModelEvaluationJob'\n",
      " |      Creates a model evaluation job running on Vertex Pipelines and returns the resulting\n",
      " |      ModelEvaluationJob resource.\n",
      " |\n",
      " |      Example usage:\n",
      " |\n",
      " |          ```\n",
      " |          my_model = Model(\n",
      " |              model_name=\"projects/123/locations/us-central1/models/456\"\n",
      " |          )\n",
      " |          my_evaluation_job = my_model.evaluate(\n",
      " |              prediction_type=\"classification\",\n",
      " |              target_field_name=\"type\",\n",
      " |              data_source_uris=[\"gs://sdk-model-eval/my-prediction-data.csv\"],\n",
      " |              staging_bucket=\"gs://my-staging-bucket/eval_pipeline_root\",\n",
      " |          )\n",
      " |          my_evaluation_job.wait()\n",
      " |          my_evaluation = my_evaluation_job.get_model_evaluation()\n",
      " |          my_evaluation.metrics\n",
      " |          ```\n",
      " |\n",
      " |      Args:\n",
      " |          prediction_type (str):\n",
      " |              Required. The problem type being addressed by this evaluation run. 'classification' and 'regression'\n",
      " |              are the currently supported problem types.\n",
      " |          target_field_name (str):\n",
      " |              Required. The column name of the field containing the label for this prediction task.\n",
      " |          gcs_source_uris (List[str]):\n",
      " |              Optional. A list of Cloud Storage data files containing the ground truth data to use for this\n",
      " |              evaluation job. These files should contain your model's prediction column. Currently only Google Cloud Storage\n",
      " |              urls are supported, for example: \"gs://path/to/your/data.csv\". The provided data files must be\n",
      " |              either CSV or JSONL. One of `gcs_source_uris` or `bigquery_source_uri` is required.\n",
      " |          bigquery_source_uri (str):\n",
      " |              Optional. A bigquery table URI containing the ground truth data to use for this evaluation job. This uri should\n",
      " |              be in the format 'bq://my-project-id.dataset.table'. One of `gcs_source_uris` or `bigquery_source_uri` is\n",
      " |              required.\n",
      " |          bigquery_destination_output_uri (str):\n",
      " |              Optional. A bigquery table URI where the Batch Prediction job associated with your Model Evaluation will write\n",
      " |              prediction output. This can be a BigQuery URI to a project ('bq://my-project'), a dataset\n",
      " |              ('bq://my-project.my-dataset'), or a table ('bq://my-project.my-dataset.my-table'). Required if `bigquery_source_uri`\n",
      " |              is provided.\n",
      " |          class_labels (List[str]):\n",
      " |              Optional. For custom (non-AutoML) classification models, a list of possible class names, in the\n",
      " |              same order that predictions are generated. This argument is required when prediction_type is 'classification'.\n",
      " |              For example, in a classification model with 3 possible classes that are outputted in the format: [0.97, 0.02, 0.01]\n",
      " |              with the class names \"cat\", \"dog\", and \"fish\", the value of `class_labels` should be `[\"cat\", \"dog\", \"fish\"]` where\n",
      " |              the class \"cat\" corresponds with 0.97 in the example above.\n",
      " |          prediction_label_column (str):\n",
      " |              Optional. The column name of the field containing classes the model is scoring. Formatted to be able to find nested\n",
      " |              columns, delimited by `.`. If not set, defaulted to `prediction.classes` for classification.\n",
      " |          prediction_score_column (str):\n",
      " |              Optional. The column name of the field containing batch prediction scores. Formatted to be able to find nested columns,\n",
      " |              delimited by `.`. If not set, defaulted to `prediction.scores` for a `classification` problem_type, `prediction.value`\n",
      " |              for a `regression` problem_type.\n",
      " |          staging_bucket (str):\n",
      " |              Optional. The GCS directory to use for staging files from this evaluation job. Defaults to the value set in\n",
      " |              aiplatform.init(staging_bucket=...) if not provided. Required if staging_bucket is not set in aiplatform.init().\n",
      " |          service_account (str):\n",
      " |              Specifies the service account for workload run-as account for this Model Evaluation PipelineJob.\n",
      " |              Users submitting jobs must have act-as permission on this run-as account. The service account running\n",
      " |              this Model Evaluation job needs the following permissions: Dataflow Worker, Storage Admin,\n",
      " |              Vertex AI Administrator, and Vertex AI Service Agent.\n",
      " |          generate_feature_attributions (boolean):\n",
      " |              Optional. Whether the model evaluation job should generate feature attributions. Defaults to False if not specified.\n",
      " |          evaluation_pipeline_display_name (str):\n",
      " |              Optional. The display name of your model evaluation job. This is the display name that will be applied to the\n",
      " |              Vertex Pipeline run for your evaluation job. If not set, a display name will be generated automatically.\n",
      " |          evaluation_metrics_display_name (str):\n",
      " |              Optional. The display name of the model evaluation resource uploaded to Vertex from your Model Evaluation pipeline.\n",
      " |          network (str):\n",
      " |              The full name of the Compute Engine network to which the job\n",
      " |              should be peered. For example, projects/12345/global/networks/myVPC.\n",
      " |              Private services access must already be configured for the network.\n",
      " |              If left unspecified, the job is not peered with any network.\n",
      " |          encryption_spec_key_name (str):\n",
      " |              Optional. The Cloud KMS resource identifier of the customer managed encryption key used to protect the job. Has the\n",
      " |              form: ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``. The key needs to be in the same\n",
      " |              region as where the compute resource is created. If this is set, then all\n",
      " |              resources created by the PipelineJob for this Model Evaluation will be encrypted with the provided encryption key.\n",
      " |              If not specified, encryption_spec of original PipelineJob will be used.\n",
      " |          experiment (Union[str, experiments_resource.Experiment]):\n",
      " |              Optional. The Vertex AI experiment name or instance to associate to the PipelineJob executing\n",
      " |              this model evaluation job. Metrics produced by the PipelineJob as system.Metric Artifacts\n",
      " |              will be associated as metrics to the provided experiment, and parameters from this PipelineJob\n",
      " |              will be associated as parameters to the provided experiment.\n",
      " |          enable_caching (bool):\n",
      " |              Optional. Whether to turn on caching for the run.\n",
      " |\n",
      " |              If this is not set, defaults to the compile time settings, which\n",
      " |              are True for all tasks by default, while users may specify\n",
      " |              different caching options for individual tasks.\n",
      " |\n",
      " |              If this is set, the setting applies to all tasks in the pipeline.\n",
      " |\n",
      " |              Overrides the compile time settings.\n",
      " |      Returns:\n",
      " |          model_evaluation.ModelEvaluationJob: Instantiated representation of the\n",
      " |          _ModelEvaluationJob.\n",
      " |      Raises:\n",
      " |          ValueError:\n",
      " |              If staging_bucket was not set in aiplatform.init() and staging_bucket was not provided.\n",
      " |              If the provided `prediction_type` is not valid.\n",
      " |              If the provided `data_source_uris` don't start with 'gs://'.\n",
      " |\n",
      " |  export_model(self, export_format_id: str, artifact_destination: Optional[str] = None, image_destination: Optional[str] = None, sync: bool = True) -> Dict[str, str]\n",
      " |      Exports a trained, exportable Model to a location specified by the user.\n",
      " |      A Model is considered to be exportable if it has at least one `supported_export_formats`.\n",
      " |      Either `artifact_destination` or `image_destination` must be provided.\n",
      " |\n",
      " |      Example Usage:\n",
      " |          my_model.export(\n",
      " |              export_format_id=\"tf-saved-model\",\n",
      " |              artifact_destination=\"gs://my-bucket/models/\"\n",
      " |          )\n",
      " |\n",
      " |          or\n",
      " |\n",
      " |          my_model.export(\n",
      " |              export_format_id=\"custom-model\",\n",
      " |              image_destination=\"us-central1-docker.pkg.dev/projectId/repo/image\"\n",
      " |          )\n",
      " |\n",
      " |      Args:\n",
      " |          export_format_id (str):\n",
      " |              Required. The ID of the format in which the Model must be exported.\n",
      " |              The list of export formats that this Model supports can be found\n",
      " |              by calling `Model.supported_export_formats`.\n",
      " |          artifact_destination (str):\n",
      " |              The Cloud Storage location where the Model artifact is to be\n",
      " |              written to. Under the directory given as the destination a\n",
      " |              new one with name\n",
      " |              \"``model-export-<model-display-name>-<timestamp-of-export-call>``\",\n",
      " |              where timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601\n",
      " |              format, will be created. Inside, the Model and any of its\n",
      " |              supporting files will be written.\n",
      " |\n",
      " |              This field should only be set when, in [Model.supported_export_formats],\n",
      " |              the value for the key given in `export_format_id` contains ``ARTIFACT``.\n",
      " |          image_destination (str):\n",
      " |              The Google Container Registry or Artifact Registry URI where\n",
      " |              the Model container image will be copied to. Accepted forms:\n",
      " |\n",
      " |              -  Google Container Registry path. For example:\n",
      " |              ``gcr.io/projectId/imageName:tag``.\n",
      " |\n",
      " |              -  Artifact Registry path. For example:\n",
      " |              ``us-central1-docker.pkg.dev/projectId/repoName/imageName:tag``.\n",
      " |\n",
      " |              This field should only be set when, in [Model.supported_export_formats],\n",
      " |              the value for the key given in `export_format_id` contains ``IMAGE``.\n",
      " |          sync (bool):\n",
      " |              Whether to execute this export synchronously. If False, this method\n",
      " |              will be executed in concurrent Future and any downstream object will\n",
      " |              be immediately returned and synced when the Future has completed.\n",
      " |\n",
      " |      Returns:\n",
      " |          output_info (Dict[str, str]):\n",
      " |              Details of the completed export with output destination paths to\n",
      " |              the artifacts or container image.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValueError: If model does not support exporting.\n",
      " |          ValueError: If invalid arguments or export formats are provided.\n",
      " |\n",
      " |  get_model_evaluation(self, evaluation_id: Optional[str] = None) -> Optional[google.cloud.aiplatform.model_evaluation.model_evaluation.ModelEvaluation]\n",
      " |      Returns a ModelEvaluation resource and instantiates its representation.\n",
      " |      If no evaluation_id is passed, it will return the first evaluation associated\n",
      " |      with this model. If the aiplatform.Model resource was instantiated with a\n",
      " |      version, this will return a Model Evaluation from that version. If no version\n",
      " |      was specified when instantiating the Model resource, this will return an\n",
      " |      Evaluation from the default version.\n",
      " |\n",
      " |      Example usage:\n",
      " |          my_model = Model(\n",
      " |              model_name=\"projects/123/locations/us-central1/models/456\"\n",
      " |          )\n",
      " |\n",
      " |          my_evaluation = my_model.get_model_evaluation(\n",
      " |              evaluation_id=\"789\"\n",
      " |          )\n",
      " |\n",
      " |          # If no arguments are passed, this method returns the first evaluation for the model\n",
      " |          my_evaluation = my_model.get_model_evaluation()\n",
      " |\n",
      " |      Args:\n",
      " |          evaluation_id (str):\n",
      " |              Optional. The ID of the model evaluation to retrieve.\n",
      " |\n",
      " |      Returns:\n",
      " |          model_evaluation.ModelEvaluation:\n",
      " |              Instantiated representation of the ModelEvaluation resource.\n",
      " |\n",
      " |  list_model_evaluations(self) -> List[ForwardRef('model_evaluation.ModelEvaluation')]\n",
      " |      List all Model Evaluation resources associated with this model.\n",
      " |      If this Model resource was instantiated with a version, the Model\n",
      " |      Evaluation resources for that version will be returned. If no version\n",
      " |      was provided when the Model resource was instantiated, Model Evaluation\n",
      " |      resources will be returned for the default version.\n",
      " |\n",
      " |      Example Usage:\n",
      " |          my_model = Model(\n",
      " |              model_name=\"projects/123/locations/us-central1/models/456@1\"\n",
      " |          )\n",
      " |\n",
      " |          my_evaluations = my_model.list_model_evaluations()\n",
      " |\n",
      " |      Returns:\n",
      " |          List[model_evaluation.ModelEvaluation]:\n",
      " |              List of ModelEvaluation resources for the model.\n",
      " |\n",
      " |  update(self, display_name: Optional[str] = None, description: Optional[str] = None, labels: Optional[Dict[str, str]] = None) -> 'Model'\n",
      " |      Updates a model.\n",
      " |\n",
      " |      Example usage:\n",
      " |          my_model = my_model.update(\n",
      " |              display_name=\"my-model\",\n",
      " |              description=\"my description\",\n",
      " |              labels={'key': 'value'},\n",
      " |          )\n",
      " |\n",
      " |      Args:\n",
      " |          display_name (str):\n",
      " |              The display name of the Model. The name can be up to 128\n",
      " |              characters long and can be consist of any UTF-8 characters.\n",
      " |          description (str):\n",
      " |              The description of the model.\n",
      " |          labels (Dict[str, str]):\n",
      " |              Optional. The labels with user-defined metadata to\n",
      " |              organize your Models.\n",
      " |              Label keys and values can be no longer than 64\n",
      " |              characters (Unicode codepoints), can only\n",
      " |              contain lowercase letters, numeric characters,\n",
      " |              underscores and dashes. International characters\n",
      " |              are allowed.\n",
      " |              See https://goo.gl/xmQnxf for more information\n",
      " |              and examples of labels.\n",
      " |\n",
      " |      Returns:\n",
      " |          model (aiplatform.Model):\n",
      " |              Updated model resource.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValueError: If `labels` is not the correct format.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |\n",
      " |  list(filter: Optional[str] = None, order_by: Optional[str] = None, project: Optional[str] = None, location: Optional[str] = None, credentials: Optional[google.auth.credentials.Credentials] = None) -> List[ForwardRef('models.Model')]\n",
      " |      List all Model resource instances.\n",
      " |\n",
      " |      Example Usage:\n",
      " |          aiplatform.Model.list(\n",
      " |              filter='labels.my_label=\"my_label_value\" AND display_name=\"my_model\"',\n",
      " |          )\n",
      " |\n",
      " |      Args:\n",
      " |          filter (str):\n",
      " |              Optional. An expression for filtering the results of the request.\n",
      " |              For field names both snake_case and camelCase are supported.\n",
      " |          order_by (str):\n",
      " |              Optional. A comma-separated list of fields to order by, sorted in\n",
      " |              ascending order. Use \"desc\" after a field name for descending.\n",
      " |              Supported fields: `display_name`, `create_time`, `update_time`\n",
      " |          project (str):\n",
      " |              Optional. Project to retrieve list from. If not set, project\n",
      " |              set in aiplatform.init will be used.\n",
      " |          location (str):\n",
      " |              Optional. Location to retrieve list from. If not set, location\n",
      " |              set in aiplatform.init will be used.\n",
      " |          credentials (auth_credentials.Credentials):\n",
      " |              Optional. Custom credentials to use to retrieve list. Overrides\n",
      " |              credentials set in aiplatform.init.\n",
      " |\n",
      " |      Returns:\n",
      " |          List[models.Model]:\n",
      " |              A list of Model resource objects\n",
      " |\n",
      " |  upload(serving_container_image_uri: Optional[str] = None, *, artifact_uri: Optional[str] = None, model_id: Optional[str] = None, parent_model: Optional[str] = None, is_default_version: bool = True, version_aliases: Optional[Sequence[str]] = None, version_description: Optional[str] = None, serving_container_predict_route: Optional[str] = None, serving_container_health_route: Optional[str] = None, serving_container_invoke_route_prefix: Optional[str] = None, description: Optional[str] = None, serving_container_command: Optional[Sequence[str]] = None, serving_container_args: Optional[Sequence[str]] = None, serving_container_environment_variables: Optional[Dict[str, str]] = None, serving_container_ports: Optional[Sequence[int]] = None, serving_container_grpc_ports: Optional[Sequence[int]] = None, local_model: Optional[ForwardRef('LocalModel')] = None, instance_schema_uri: Optional[str] = None, parameters_schema_uri: Optional[str] = None, prediction_schema_uri: Optional[str] = None, explanation_metadata: Optional[google.cloud.aiplatform_v1.types.explanation_metadata.ExplanationMetadata] = None, explanation_parameters: Optional[google.cloud.aiplatform_v1.types.explanation.ExplanationParameters] = None, display_name: Optional[str] = None, project: Optional[str] = None, location: Optional[str] = None, credentials: Optional[google.auth.credentials.Credentials] = None, labels: Optional[Dict[str, str]] = None, encryption_spec_key_name: Optional[str] = None, staging_bucket: Optional[str] = None, sync=True, upload_request_timeout: Optional[float] = None, serving_container_deployment_timeout: Optional[int] = None, serving_container_shared_memory_size_mb: Optional[int] = None, serving_container_startup_probe_exec: Optional[Sequence[str]] = None, serving_container_startup_probe_period_seconds: Optional[int] = None, serving_container_startup_probe_timeout_seconds: Optional[int] = None, serving_container_health_probe_exec: Optional[Sequence[str]] = None, serving_container_health_probe_period_seconds: Optional[int] = None, serving_container_health_probe_timeout_seconds: Optional[int] = None, model_garden_source_model_name: Optional[str] = None, model_garden_source_model_version_id: Optional[str] = None) -> 'Model'\n",
      " |      Uploads a model and returns a Model representing the uploaded Model\n",
      " |      resource.\n",
      " |\n",
      " |      Example usage:\n",
      " |          my_model = Model.upload(\n",
      " |              display_name=\"my-model\",\n",
      " |              artifact_uri=\"gs://my-model/saved-model\",\n",
      " |              serving_container_image_uri=\"tensorflow/serving\"\n",
      " |          )\n",
      " |\n",
      " |      Args:\n",
      " |          serving_container_image_uri (str):\n",
      " |              Optional. The URI of the Model serving container. This parameter is required\n",
      " |              if the parameter `local_model` is not specified.\n",
      " |          artifact_uri (str):\n",
      " |              Optional. The path to the directory containing the Model artifact and\n",
      " |              any of its supporting files. Leave blank for custom container prediction.\n",
      " |              Not present for AutoML Models.\n",
      " |          model_id (str):\n",
      " |              Optional. The ID to use for the uploaded Model, which will\n",
      " |              become the final component of the model resource name.\n",
      " |              This value may be up to 63 characters, and valid characters\n",
      " |              are `[a-z0-9_-]`. The first character cannot be a number or hyphen.\n",
      " |          parent_model (str):\n",
      " |              Optional. The resource name or model ID of an existing model that the\n",
      " |              newly-uploaded model will be a version of.\n",
      " |\n",
      " |              Only set this field when uploading a new version of an existing model.\n",
      " |          is_default_version (bool):\n",
      " |              Optional. When set to True, the newly uploaded model version will\n",
      " |              automatically have alias \"default\" included. Subsequent uses of\n",
      " |              this model without a version specified will use this \"default\" version.\n",
      " |\n",
      " |              When set to False, the \"default\" alias will not be moved.\n",
      " |              Actions targeting the newly-uploaded model version will need\n",
      " |              to specifically reference this version by ID or alias.\n",
      " |\n",
      " |              New model uploads, i.e. version 1, will always be \"default\" aliased.\n",
      " |          version_aliases (Sequence[str]):\n",
      " |              Optional. User provided version aliases so that a model version\n",
      " |              can be referenced via alias instead of auto-generated version ID.\n",
      " |              A default version alias will be created for the first version of the model.\n",
      " |\n",
      " |              The format is [a-z][a-zA-Z0-9-]{0,126}[a-z0-9]\n",
      " |          version_description (str):\n",
      " |              Optional. The description of the model version being uploaded.\n",
      " |          serving_container_predict_route (str):\n",
      " |              Optional. An HTTP path to send prediction requests to the container, and\n",
      " |              which must be supported by it. If not specified a default HTTP path will\n",
      " |              be used by Vertex AI.\n",
      " |          serving_container_health_route (str):\n",
      " |              Optional. An HTTP path to send health check requests to the container, and which\n",
      " |              must be supported by it. If not specified a standard HTTP path will be\n",
      " |              used by Vertex AI.\n",
      " |          serving_container_invoke_route_prefix (str):\n",
      " |              Optional. Invoke route prefix for the custom container. \"/*\" is the only\n",
      " |              supported value right now. By setting this field, any non-root route on\n",
      " |              this model will be accessible with invoke http call\n",
      " |              eg: \"/invoke/foo/bar\", however the [PredictionService.Invoke] RPC is not\n",
      " |              supported yet.\n",
      " |          description (str):\n",
      " |              The description of the model.\n",
      " |          serving_container_command: Optional[Sequence[str]]=None,\n",
      " |              The command with which the container is run. Not executed within a\n",
      " |              shell. The Docker image's ENTRYPOINT is used if this is not provided.\n",
      " |              Variable references $(VAR_NAME) are expanded using the container's\n",
      " |              environment. If a variable cannot be resolved, the reference in the\n",
      " |              input string will be unchanged. The $(VAR_NAME) syntax can be escaped\n",
      " |              with a double $$, ie: $$(VAR_NAME). Escaped references will never be\n",
      " |              expanded, regardless of whether the variable exists or not.\n",
      " |          serving_container_args: Optional[Sequence[str]]=None,\n",
      " |              The arguments to the command. The Docker image's CMD is used if this is\n",
      " |              not provided. Variable references $(VAR_NAME) are expanded using the\n",
      " |              container's environment. If a variable cannot be resolved, the reference\n",
      " |              in the input string will be unchanged. The $(VAR_NAME) syntax can be\n",
      " |              escaped with a double $$, ie: $$(VAR_NAME). Escaped references will\n",
      " |              never be expanded, regardless of whether the variable exists or not.\n",
      " |          serving_container_environment_variables: Optional[Dict[str, str]]=None,\n",
      " |              The environment variables that are to be present in the container.\n",
      " |              Should be a dictionary where keys are environment variable names\n",
      " |              and values are environment variable values for those names.\n",
      " |          serving_container_ports: Optional[Sequence[int]]=None,\n",
      " |              Declaration of ports that are exposed by the container. This field is\n",
      " |              primarily informational, it gives Vertex AI information about the\n",
      " |              network connections the container uses. Listing or not a port here has\n",
      " |              no impact on whether the port is actually exposed, any port listening on\n",
      " |              the default \"0.0.0.0\" address inside a container will be accessible from\n",
      " |              the network.\n",
      " |          serving_container_grpc_ports: Optional[Sequence[int]]=None,\n",
      " |              Declaration of ports that are exposed by the container. Vertex AI sends gRPC\n",
      " |              prediction requests that it receives to the first port on this list. Vertex\n",
      " |              AI also sends liveness and health checks to this port.\n",
      " |              If you do not specify this field, gRPC requests to the container will be\n",
      " |              disabled.\n",
      " |              Vertex AI does not use ports other than the first one listed. This field\n",
      " |              corresponds to the `ports` field of the Kubernetes Containers v1 core API.\n",
      " |          local_model (Optional[LocalModel]):\n",
      " |              Optional. A LocalModel instance that includes a `serving_container_spec`.\n",
      " |              If provided, the `serving_container_spec` of the LocalModel instance\n",
      " |              will overwrite the values of all other serving container parameters.\n",
      " |          instance_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the format of a single instance, which\n",
      " |              are used in\n",
      " |              ``PredictRequest.instances``,\n",
      " |              ``ExplainRequest.instances``\n",
      " |              and\n",
      " |              ``BatchPredictionJob.input_config``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform. Note: The URI given on output will be immutable\n",
      " |              and probably different, including the URI scheme, than the\n",
      " |              one given on input. The output URI will point to a location\n",
      " |              where the user only has a read access.\n",
      " |          parameters_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the parameters of prediction and\n",
      " |              explanation via\n",
      " |              ``PredictRequest.parameters``,\n",
      " |              ``ExplainRequest.parameters``\n",
      " |              and\n",
      " |              ``BatchPredictionJob.model_parameters``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform, if no parameters are supported it is set to an\n",
      " |              empty string. Note: The URI given on output will be\n",
      " |              immutable and probably different, including the URI scheme,\n",
      " |              than the one given on input. The output URI will point to a\n",
      " |              location where the user only has a read access.\n",
      " |          prediction_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the format of a single prediction\n",
      " |              produced by this Model, which are returned via\n",
      " |              ``PredictResponse.predictions``,\n",
      " |              ``ExplainResponse.explanations``,\n",
      " |              and\n",
      " |              ``BatchPredictionJob.output_config``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform. Note: The URI given on output will be immutable\n",
      " |              and probably different, including the URI scheme, than the\n",
      " |              one given on input. The output URI will point to a location\n",
      " |              where the user only has a read access.\n",
      " |          explanation_metadata (aiplatform.explain.ExplanationMetadata):\n",
      " |              Optional. Metadata describing the Model's input and output for explanation.\n",
      " |              `explanation_metadata` is optional while `explanation_parameters` must be\n",
      " |              specified when used.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1igh60kt>`\n",
      " |          explanation_parameters (aiplatform.explain.ExplanationParameters):\n",
      " |              Optional. Parameters to configure explaining for Model's predictions.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1an4zake>`\n",
      " |          display_name (str):\n",
      " |              Optional. The display name of the Model. The name can be up to 128\n",
      " |              characters long and can be consist of any UTF-8 characters.\n",
      " |          project: Optional[str]=None,\n",
      " |              Project to upload this model to. Overrides project set in\n",
      " |              aiplatform.init.\n",
      " |          location: Optional[str]=None,\n",
      " |              Location to upload this model to. Overrides location set in\n",
      " |              aiplatform.init.\n",
      " |          credentials: Optional[auth_credentials.Credentials]=None,\n",
      " |              Custom credentials to use to upload this model. Overrides credentials\n",
      " |              set in aiplatform.init.\n",
      " |          labels (Dict[str, str]):\n",
      " |              Optional. The labels with user-defined metadata to\n",
      " |              organize your Models.\n",
      " |              Label keys and values can be no longer than 64\n",
      " |              characters (Unicode codepoints), can only\n",
      " |              contain lowercase letters, numeric characters,\n",
      " |              underscores and dashes. International characters\n",
      " |              are allowed.\n",
      " |              See https://goo.gl/xmQnxf for more information\n",
      " |              and examples of labels.\n",
      " |          encryption_spec_key_name (Optional[str]):\n",
      " |              Optional. The Cloud KMS resource identifier of the customer\n",
      " |              managed encryption key used to protect the model. Has the\n",
      " |              form:\n",
      " |              ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.\n",
      " |              The key needs to be in the same region as where the compute\n",
      " |              resource is created.\n",
      " |\n",
      " |              If set, this Model and all sub-resources of this Model will be secured by this key.\n",
      " |\n",
      " |              Overrides encryption_spec_key_name set in aiplatform.init.\n",
      " |          staging_bucket (str):\n",
      " |              Optional. Bucket to stage local model artifacts. Overrides\n",
      " |              staging_bucket set in aiplatform.init.\n",
      " |          upload_request_timeout (float):\n",
      " |              Optional. The timeout for the upload request in seconds.\n",
      " |          serving_container_deployment_timeout (int):\n",
      " |              Optional. Deployment timeout in seconds.\n",
      " |          serving_container_shared_memory_size_mb (int):\n",
      " |              Optional. The amount of the VM memory to reserve as the shared\n",
      " |              memory for the model in megabytes.\n",
      " |          serving_container_startup_probe_exec (Sequence[str]):\n",
      " |              Optional. Exec specifies the action to take. Used by startup\n",
      " |              probe. An example of this argument would be\n",
      " |              [\"cat\", \"/tmp/healthy\"]\n",
      " |          serving_container_startup_probe_period_seconds (int):\n",
      " |              Optional. How often (in seconds) to perform the startup probe.\n",
      " |              Default to 10 seconds. Minimum value is 1.\n",
      " |          serving_container_startup_probe_timeout_seconds (int):\n",
      " |              Optional. Number of seconds after which the startup probe times\n",
      " |              out. Defaults to 1 second. Minimum value is 1.\n",
      " |          serving_container_health_probe_exec (Sequence[str]):\n",
      " |              Optional. Exec specifies the action to take. Used by health\n",
      " |              probe. An example of this argument would be\n",
      " |              [\"cat\", \"/tmp/healthy\"]\n",
      " |          serving_container_health_probe_period_seconds (int):\n",
      " |              Optional. How often (in seconds) to perform the health probe.\n",
      " |              Default to 10 seconds. Minimum value is 1.\n",
      " |          serving_container_health_probe_timeout_seconds (int):\n",
      " |              Optional. Number of seconds after which the health probe times\n",
      " |              out. Defaults to 1 second. Minimum value is 1.\n",
      " |          model_garden_source_model_name:\n",
      " |              Optional. The model garden source model resource name if the\n",
      " |              model is from Vertex Model Garden.\n",
      " |          model_garden_source_model_version_id:\n",
      " |              Optional. The model garden source model version id if the\n",
      " |              model is from Vertex Model Garden.\n",
      " |\n",
      " |      Returns:\n",
      " |          model (aiplatform.Model):\n",
      " |              Instantiated representation of the uploaded model resource.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValueError: If explanation_metadata is specified while explanation_parameters\n",
      " |              is not.\n",
      " |\n",
      " |              Also if model directory does not contain a supported model file.\n",
      " |              If `local_model` is specified but `serving_container_spec.image_uri`\n",
      " |              in the `local_model` is None.\n",
      " |              If `local_model` is not specified and `serving_container_image_uri`\n",
      " |              is None.\n",
      " |\n",
      " |  upload_scikit_learn_model_file(model_file_path: str, sklearn_version: Optional[str] = None, display_name: Optional[str] = None, description: Optional[str] = None, model_id: Optional[str] = None, parent_model: Optional[str] = None, is_default_version: Optional[bool] = True, version_aliases: Optional[Sequence[str]] = None, version_description: Optional[str] = None, instance_schema_uri: Optional[str] = None, parameters_schema_uri: Optional[str] = None, prediction_schema_uri: Optional[str] = None, explanation_metadata: Optional[google.cloud.aiplatform_v1.types.explanation_metadata.ExplanationMetadata] = None, explanation_parameters: Optional[google.cloud.aiplatform_v1.types.explanation.ExplanationParameters] = None, project: Optional[str] = None, location: Optional[str] = None, credentials: Optional[google.auth.credentials.Credentials] = None, labels: Optional[Dict[str, str]] = None, encryption_spec_key_name: Optional[str] = None, staging_bucket: Optional[str] = None, sync=True, upload_request_timeout: Optional[float] = None) -> 'Model'\n",
      " |      Uploads a model and returns a Model representing the uploaded Model\n",
      " |      resource.\n",
      " |\n",
      " |      Example usage:\n",
      " |          my_model = Model.upload_scikit_learn_model_file(\n",
      " |              model_file_path=\"iris.sklearn_model.joblib\"\n",
      " |          )\n",
      " |\n",
      " |      Args:\n",
      " |          model_file_path (str): Required. Local file path of the model.\n",
      " |          sklearn_version (str):\n",
      " |              Optional. The version of the Scikit-learn serving container.\n",
      " |              Supported versions: [\"0.20\", \"0.22\", \"0.23\", \"0.24\", \"1.0\"].\n",
      " |              If the version is not specified, the latest version is used.\n",
      " |          display_name (str):\n",
      " |              Optional. The display name of the Model. The name can be up to 128\n",
      " |              characters long and can be consist of any UTF-8 characters.\n",
      " |          description (str):\n",
      " |              The description of the model.\n",
      " |          model_id (str):\n",
      " |              Optional. The ID to use for the uploaded Model, which will\n",
      " |              become the final component of the model resource name.\n",
      " |              This value may be up to 63 characters, and valid characters\n",
      " |              are `[a-z0-9_-]`. The first character cannot be a number or hyphen.\n",
      " |          parent_model (str):\n",
      " |              Optional. The resource name or model ID of an existing model that the\n",
      " |              newly-uploaded model will be a version of.\n",
      " |\n",
      " |              Only set this field when uploading a new version of an existing model.\n",
      " |          is_default_version (bool):\n",
      " |              Optional. When set to True, the newly uploaded model version will\n",
      " |              automatically have alias \"default\" included. Subsequent uses of\n",
      " |              this model without a version specified will use this \"default\" version.\n",
      " |\n",
      " |              When set to False, the \"default\" alias will not be moved.\n",
      " |              Actions targeting the newly-uploaded model version will need\n",
      " |              to specifically reference this version by ID or alias.\n",
      " |\n",
      " |              New model uploads, i.e. version 1, will always be \"default\" aliased.\n",
      " |          version_aliases (Sequence[str]):\n",
      " |              Optional. User provided version aliases so that a model version\n",
      " |              can be referenced via alias instead of auto-generated version ID.\n",
      " |              A default version alias will be created for the first version of the model.\n",
      " |\n",
      " |              The format is [a-z][a-zA-Z0-9-]{0,126}[a-z0-9]\n",
      " |          version_description (str):\n",
      " |              Optional. The description of the model version being uploaded.\n",
      " |          instance_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the format of a single instance, which\n",
      " |              are used in\n",
      " |              ``PredictRequest.instances``,\n",
      " |              ``ExplainRequest.instances``\n",
      " |              and\n",
      " |              ``BatchPredictionJob.input_config``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform. Note: The URI given on output will be immutable\n",
      " |              and probably different, including the URI scheme, than the\n",
      " |              one given on input. The output URI will point to a location\n",
      " |              where the user only has a read access.\n",
      " |          parameters_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the parameters of prediction and\n",
      " |              explanation via\n",
      " |              ``PredictRequest.parameters``,\n",
      " |              ``ExplainRequest.parameters``\n",
      " |              and\n",
      " |              ``BatchPredictionJob.model_parameters``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform, if no parameters are supported it is set to an\n",
      " |              empty string. Note: The URI given on output will be\n",
      " |              immutable and probably different, including the URI scheme,\n",
      " |              than the one given on input. The output URI will point to a\n",
      " |              location where the user only has a read access.\n",
      " |          prediction_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the format of a single prediction\n",
      " |              produced by this Model, which are returned via\n",
      " |              ``PredictResponse.predictions``,\n",
      " |              ``ExplainResponse.explanations``,\n",
      " |              and\n",
      " |              ``BatchPredictionJob.output_config``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform. Note: The URI given on output will be immutable\n",
      " |              and probably different, including the URI scheme, than the\n",
      " |              one given on input. The output URI will point to a location\n",
      " |              where the user only has a read access.\n",
      " |          explanation_metadata (aiplatform.explain.ExplanationMetadata):\n",
      " |              Optional. Metadata describing the Model's input and output for explanation.\n",
      " |              `explanation_metadata` is optional while `explanation_parameters` must be\n",
      " |              specified when used.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1igh60kt>`\n",
      " |          explanation_parameters (aiplatform.explain.ExplanationParameters):\n",
      " |              Optional. Parameters to configure explaining for Model's predictions.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1an4zake>`\n",
      " |          project: Optional[str]=None,\n",
      " |              Project to upload this model to. Overrides project set in\n",
      " |              aiplatform.init.\n",
      " |          location: Optional[str]=None,\n",
      " |              Location to upload this model to. Overrides location set in\n",
      " |              aiplatform.init.\n",
      " |          credentials: Optional[auth_credentials.Credentials]=None,\n",
      " |              Custom credentials to use to upload this model. Overrides credentials\n",
      " |              set in aiplatform.init.\n",
      " |          labels (Dict[str, str]):\n",
      " |              Optional. The labels with user-defined metadata to\n",
      " |              organize your Models.\n",
      " |              Label keys and values can be no longer than 64\n",
      " |              characters (Unicode codepoints), can only\n",
      " |              contain lowercase letters, numeric characters,\n",
      " |              underscores and dashes. International characters\n",
      " |              are allowed.\n",
      " |              See https://goo.gl/xmQnxf for more information\n",
      " |              and examples of labels.\n",
      " |          encryption_spec_key_name (Optional[str]):\n",
      " |              Optional. The Cloud KMS resource identifier of the customer\n",
      " |              managed encryption key used to protect the model. Has the\n",
      " |              form:\n",
      " |              ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.\n",
      " |              The key needs to be in the same region as where the compute\n",
      " |              resource is created.\n",
      " |\n",
      " |              If set, this Model and all sub-resources of this Model will be secured by this key.\n",
      " |\n",
      " |              Overrides encryption_spec_key_name set in aiplatform.init.\n",
      " |          staging_bucket (str):\n",
      " |              Optional. Bucket to stage local model artifacts. Overrides\n",
      " |              staging_bucket set in aiplatform.init.\n",
      " |          sync (bool):\n",
      " |              Whether to execute this method synchronously. If False, this method\n",
      " |              will be executed in concurrent Future and any downstream object will\n",
      " |              be immediately returned and synced when the Future has completed.\n",
      " |          upload_request_timeout (float):\n",
      " |              Optional. The timeout for the upload request in seconds.\n",
      " |\n",
      " |      Returns:\n",
      " |          model (aiplatform.Model):\n",
      " |              Instantiated representation of the uploaded model resource.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValueError: If explanation_metadata is specified while explanation_parameters\n",
      " |              is not. Also if model directory does not contain a supported model file.\n",
      " |\n",
      " |  upload_tensorflow_saved_model(saved_model_dir: str, tensorflow_version: Optional[str] = None, use_gpu: bool = False, display_name: Optional[str] = None, description: Optional[str] = None, model_id: Optional[str] = None, parent_model: Optional[str] = None, is_default_version: Optional[bool] = True, version_aliases: Optional[Sequence[str]] = None, version_description: Optional[str] = None, instance_schema_uri: Optional[str] = None, parameters_schema_uri: Optional[str] = None, prediction_schema_uri: Optional[str] = None, explanation_metadata: Optional[google.cloud.aiplatform_v1.types.explanation_metadata.ExplanationMetadata] = None, explanation_parameters: Optional[google.cloud.aiplatform_v1.types.explanation.ExplanationParameters] = None, project: Optional[str] = None, location: Optional[str] = None, credentials: Optional[google.auth.credentials.Credentials] = None, labels: Optional[Dict[str, str]] = None, encryption_spec_key_name: Optional[str] = None, staging_bucket: Optional[str] = None, sync=True, upload_request_timeout: Optional[str] = None) -> 'Model'\n",
      " |      Uploads a model and returns a Model representing the uploaded Model\n",
      " |      resource.\n",
      " |\n",
      " |      Example usage:\n",
      " |          my_model = Model.upload_scikit_learn_model_file(\n",
      " |              model_file_path=\"iris.tensorflow_model.SavedModel\"\n",
      " |          )\n",
      " |\n",
      " |      Args:\n",
      " |          saved_model_dir (str): Required.\n",
      " |              Local directory of the Tensorflow SavedModel.\n",
      " |          tensorflow_version (str):\n",
      " |              Optional. The version of the Tensorflow serving container.\n",
      " |              Supported versions: [\"0.15\", \"2.1\", \"2.2\", \"2.3\", \"2.4\", \"2.5\", \"2.6\", \"2.7\"].\n",
      " |              If the version is not specified, the latest version is used.\n",
      " |          use_gpu (bool): Whether to use GPU for model serving.\n",
      " |          display_name (str):\n",
      " |              Optional. The display name of the Model. The name can be up to 128\n",
      " |              characters long and can be consist of any UTF-8 characters.\n",
      " |          description (str):\n",
      " |              The description of the model.\n",
      " |          model_id (str):\n",
      " |              Optional. The ID to use for the uploaded Model, which will\n",
      " |              become the final component of the model resource name.\n",
      " |              This value may be up to 63 characters, and valid characters\n",
      " |              are `[a-z0-9_-]`. The first character cannot be a number or hyphen.\n",
      " |          parent_model (str):\n",
      " |              Optional. The resource name or model ID of an existing model that the\n",
      " |              newly-uploaded model will be a version of.\n",
      " |\n",
      " |              Only set this field when uploading a new version of an existing model.\n",
      " |          is_default_version (bool):\n",
      " |              Optional. When set to True, the newly uploaded model version will\n",
      " |              automatically have alias \"default\" included. Subsequent uses of\n",
      " |              this model without a version specified will use this \"default\" version.\n",
      " |\n",
      " |              When set to False, the \"default\" alias will not be moved.\n",
      " |              Actions targeting the newly-uploaded model version will need\n",
      " |              to specifically reference this version by ID or alias.\n",
      " |\n",
      " |              New model uploads, i.e. version 1, will always be \"default\" aliased.\n",
      " |          version_aliases (Sequence[str]):\n",
      " |              Optional. User provided version aliases so that a model version\n",
      " |              can be referenced via alias instead of auto-generated version ID.\n",
      " |              A default version alias will be created for the first version of the model.\n",
      " |\n",
      " |              The format is [a-z][a-zA-Z0-9-]{0,126}[a-z0-9]\n",
      " |          version_description (str):\n",
      " |              Optional. The description of the model version being uploaded.\n",
      " |          instance_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the format of a single instance, which\n",
      " |              are used in\n",
      " |              ``PredictRequest.instances``,\n",
      " |              ``ExplainRequest.instances``\n",
      " |              and\n",
      " |              ``BatchPredictionJob.input_config``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform. Note: The URI given on output will be immutable\n",
      " |              and probably different, including the URI scheme, than the\n",
      " |              one given on input. The output URI will point to a location\n",
      " |              where the user only has a read access.\n",
      " |          parameters_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the parameters of prediction and\n",
      " |              explanation via\n",
      " |              ``PredictRequest.parameters``,\n",
      " |              ``ExplainRequest.parameters``\n",
      " |              and\n",
      " |              ``BatchPredictionJob.model_parameters``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform, if no parameters are supported it is set to an\n",
      " |              empty string. Note: The URI given on output will be\n",
      " |              immutable and probably different, including the URI scheme,\n",
      " |              than the one given on input. The output URI will point to a\n",
      " |              location where the user only has a read access.\n",
      " |          prediction_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the format of a single prediction\n",
      " |              produced by this Model, which are returned via\n",
      " |              ``PredictResponse.predictions``,\n",
      " |              ``ExplainResponse.explanations``,\n",
      " |              and\n",
      " |              ``BatchPredictionJob.output_config``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform. Note: The URI given on output will be immutable\n",
      " |              and probably different, including the URI scheme, than the\n",
      " |              one given on input. The output URI will point to a location\n",
      " |              where the user only has a read access.\n",
      " |          explanation_metadata (aiplatform.explain.ExplanationMetadata):\n",
      " |              Optional. Metadata describing the Model's input and output for explanation.\n",
      " |              `explanation_metadata` is optional while `explanation_parameters` must be\n",
      " |              specified when used.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1igh60kt>`\n",
      " |          explanation_parameters (aiplatform.explain.ExplanationParameters):\n",
      " |              Optional. Parameters to configure explaining for Model's predictions.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1an4zake>`\n",
      " |          project: Optional[str]=None,\n",
      " |              Project to upload this model to. Overrides project set in\n",
      " |              aiplatform.init.\n",
      " |          location: Optional[str]=None,\n",
      " |              Location to upload this model to. Overrides location set in\n",
      " |              aiplatform.init.\n",
      " |          credentials: Optional[auth_credentials.Credentials]=None,\n",
      " |              Custom credentials to use to upload this model. Overrides credentials\n",
      " |              set in aiplatform.init.\n",
      " |          labels (Dict[str, str]):\n",
      " |              Optional. The labels with user-defined metadata to\n",
      " |              organize your Models.\n",
      " |              Label keys and values can be no longer than 64\n",
      " |              characters (Unicode codepoints), can only\n",
      " |              contain lowercase letters, numeric characters,\n",
      " |              underscores and dashes. International characters\n",
      " |              are allowed.\n",
      " |              See https://goo.gl/xmQnxf for more information\n",
      " |              and examples of labels.\n",
      " |          encryption_spec_key_name (Optional[str]):\n",
      " |              Optional. The Cloud KMS resource identifier of the customer\n",
      " |              managed encryption key used to protect the model. Has the\n",
      " |              form:\n",
      " |              ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.\n",
      " |              The key needs to be in the same region as where the compute\n",
      " |              resource is created.\n",
      " |\n",
      " |              If set, this Model and all sub-resources of this Model will be secured by this key.\n",
      " |\n",
      " |              Overrides encryption_spec_key_name set in aiplatform.init.\n",
      " |          staging_bucket (str):\n",
      " |              Optional. Bucket to stage local model artifacts. Overrides\n",
      " |              staging_bucket set in aiplatform.init.\n",
      " |          sync (bool):\n",
      " |              Whether to execute this method synchronously. If False, this method\n",
      " |              will be executed in concurrent Future and any downstream object will\n",
      " |              be immediately returned and synced when the Future has completed.\n",
      " |          upload_request_timeout (float):\n",
      " |              Optional. The timeout for the upload request in seconds.\n",
      " |\n",
      " |      Returns:\n",
      " |          model (aiplatform.Model):\n",
      " |              Instantiated representation of the uploaded model resource.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValueError: If explanation_metadata is specified while explanation_parameters\n",
      " |              is not. Also if model directory does not contain a supported model file.\n",
      " |\n",
      " |  upload_xgboost_model_file(model_file_path: str, xgboost_version: Optional[str] = None, display_name: Optional[str] = None, description: Optional[str] = None, model_id: Optional[str] = None, parent_model: Optional[str] = None, is_default_version: Optional[bool] = True, version_aliases: Optional[Sequence[str]] = None, version_description: Optional[str] = None, instance_schema_uri: Optional[str] = None, parameters_schema_uri: Optional[str] = None, prediction_schema_uri: Optional[str] = None, explanation_metadata: Optional[google.cloud.aiplatform_v1.types.explanation_metadata.ExplanationMetadata] = None, explanation_parameters: Optional[google.cloud.aiplatform_v1.types.explanation.ExplanationParameters] = None, project: Optional[str] = None, location: Optional[str] = None, credentials: Optional[google.auth.credentials.Credentials] = None, labels: Optional[Dict[str, str]] = None, encryption_spec_key_name: Optional[str] = None, staging_bucket: Optional[str] = None, sync=True, upload_request_timeout: Optional[float] = None) -> 'Model'\n",
      " |      Uploads a model and returns a Model representing the uploaded Model\n",
      " |      resource.\n",
      " |\n",
      " |      Example usage:\n",
      " |          my_model = Model.upload_xgboost_model_file(\n",
      " |              model_file_path=\"iris.xgboost_model.bst\"\n",
      " |          )\n",
      " |\n",
      " |      Args:\n",
      " |          model_file_path (str): Required. Local file path of the model.\n",
      " |          xgboost_version (str): Optional. The version of the XGBoost serving container.\n",
      " |              Supported versions: [\"0.82\", \"0.90\", \"1.1\", \"1.2\", \"1.3\", \"1.4\"].\n",
      " |              If the version is not specified, the latest version is used.\n",
      " |          display_name (str):\n",
      " |              Optional. The display name of the Model. The name can be up to 128\n",
      " |              characters long and can be consist of any UTF-8 characters.\n",
      " |          description (str):\n",
      " |              The description of the model.\n",
      " |          model_id (str):\n",
      " |              Optional. The ID to use for the uploaded Model, which will\n",
      " |              become the final component of the model resource name.\n",
      " |              This value may be up to 63 characters, and valid characters\n",
      " |              are `[a-z0-9_-]`. The first character cannot be a number or hyphen.\n",
      " |          parent_model (str):\n",
      " |              Optional. The resource name or model ID of an existing model that the\n",
      " |              newly-uploaded model will be a version of.\n",
      " |\n",
      " |              Only set this field when uploading a new version of an existing model.\n",
      " |          is_default_version (bool):\n",
      " |              Optional. When set to True, the newly uploaded model version will\n",
      " |              automatically have alias \"default\" included. Subsequent uses of\n",
      " |              this model without a version specified will use this \"default\" version.\n",
      " |\n",
      " |              When set to False, the \"default\" alias will not be moved.\n",
      " |              Actions targeting the newly-uploaded model version will need\n",
      " |              to specifically reference this version by ID or alias.\n",
      " |\n",
      " |              New model uploads, i.e. version 1, will always be \"default\" aliased.\n",
      " |          version_aliases (Sequence[str]):\n",
      " |              Optional. User provided version aliases so that a model version\n",
      " |              can be referenced via alias instead of auto-generated version ID.\n",
      " |              A default version alias will be created for the first version of the model.\n",
      " |\n",
      " |              The format is [a-z][a-zA-Z0-9-]{0,126}[a-z0-9]\n",
      " |          version_description (str):\n",
      " |              Optional. The description of the model version being uploaded.\n",
      " |          instance_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the format of a single instance, which\n",
      " |              are used in\n",
      " |              ``PredictRequest.instances``,\n",
      " |              ``ExplainRequest.instances``\n",
      " |              and\n",
      " |              ``BatchPredictionJob.input_config``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform. Note: The URI given on output will be immutable\n",
      " |              and probably different, including the URI scheme, than the\n",
      " |              one given on input. The output URI will point to a location\n",
      " |              where the user only has a read access.\n",
      " |          parameters_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the parameters of prediction and\n",
      " |              explanation via\n",
      " |              ``PredictRequest.parameters``,\n",
      " |              ``ExplainRequest.parameters``\n",
      " |              and\n",
      " |              ``BatchPredictionJob.model_parameters``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform, if no parameters are supported it is set to an\n",
      " |              empty string. Note: The URI given on output will be\n",
      " |              immutable and probably different, including the URI scheme,\n",
      " |              than the one given on input. The output URI will point to a\n",
      " |              location where the user only has a read access.\n",
      " |          prediction_schema_uri (str):\n",
      " |              Optional. Points to a YAML file stored on Google Cloud\n",
      " |              Storage describing the format of a single prediction\n",
      " |              produced by this Model, which are returned via\n",
      " |              ``PredictResponse.predictions``,\n",
      " |              ``ExplainResponse.explanations``,\n",
      " |              and\n",
      " |              ``BatchPredictionJob.output_config``.\n",
      " |              The schema is defined as an OpenAPI 3.0.2 `Schema\n",
      " |              Object <https://tinyurl.com/y538mdwt#schema-object>`__.\n",
      " |              AutoML Models always have this field populated by AI\n",
      " |              Platform. Note: The URI given on output will be immutable\n",
      " |              and probably different, including the URI scheme, than the\n",
      " |              one given on input. The output URI will point to a location\n",
      " |              where the user only has a read access.\n",
      " |          explanation_metadata (aiplatform.explain.ExplanationMetadata):\n",
      " |              Optional. Metadata describing the Model's input and output for explanation.\n",
      " |              `explanation_metadata` is optional while `explanation_parameters` must be\n",
      " |              specified when used.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1igh60kt>`\n",
      " |          explanation_parameters (aiplatform.explain.ExplanationParameters):\n",
      " |              Optional. Parameters to configure explaining for Model's predictions.\n",
      " |              For more details, see `Ref docs <http://tinyurl.com/1an4zake>`\n",
      " |          project: Optional[str]=None,\n",
      " |              Project to upload this model to. Overrides project set in\n",
      " |              aiplatform.init.\n",
      " |          location: Optional[str]=None,\n",
      " |              Location to upload this model to. Overrides location set in\n",
      " |              aiplatform.init.\n",
      " |          credentials: Optional[auth_credentials.Credentials]=None,\n",
      " |              Custom credentials to use to upload this model. Overrides credentials\n",
      " |              set in aiplatform.init.\n",
      " |          labels (Dict[str, str]):\n",
      " |              Optional. The labels with user-defined metadata to\n",
      " |              organize your Models.\n",
      " |              Label keys and values can be no longer than 64\n",
      " |              characters (Unicode codepoints), can only\n",
      " |              contain lowercase letters, numeric characters,\n",
      " |              underscores and dashes. International characters\n",
      " |              are allowed.\n",
      " |              See https://goo.gl/xmQnxf for more information\n",
      " |              and examples of labels.\n",
      " |          encryption_spec_key_name (Optional[str]):\n",
      " |              Optional. The Cloud KMS resource identifier of the customer\n",
      " |              managed encryption key used to protect the model. Has the\n",
      " |              form:\n",
      " |              ``projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key``.\n",
      " |              The key needs to be in the same region as where the compute\n",
      " |              resource is created.\n",
      " |\n",
      " |              If set, this Model and all sub-resources of this Model will be secured by this key.\n",
      " |\n",
      " |              Overrides encryption_spec_key_name set in aiplatform.init.\n",
      " |          staging_bucket (str):\n",
      " |              Optional. Bucket to stage local model artifacts. Overrides\n",
      " |              staging_bucket set in aiplatform.init.\n",
      " |          upload_request_timeout (float):\n",
      " |              Optional. The timeout for the upload request in seconds.\n",
      " |\n",
      " |      Returns:\n",
      " |          model (aiplatform.Model):\n",
      " |              Instantiated representation of the uploaded model resource.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValueError: If model directory does not contain a supported model file.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  container_spec\n",
      " |      The specification of the container that is to be used when deploying\n",
      " |      this Model. Not present for AutoML Models.\n",
      " |\n",
      " |  description\n",
      " |      Description of the model.\n",
      " |\n",
      " |  name\n",
      " |      Name of this resource.\n",
      " |\n",
      " |  predict_schemata\n",
      " |      The schemata that describe formats of the Model's predictions and\n",
      " |      explanations, if available.\n",
      " |\n",
      " |  preview\n",
      " |      Return a Model instance with preview features enabled.\n",
      " |\n",
      " |  resource_name\n",
      " |      Full qualified resource name, without any version ID.\n",
      " |\n",
      " |  supported_deployment_resources_types\n",
      " |      List of deployment resource types accepted for this Model.\n",
      " |\n",
      " |      When this Model is deployed, its prediction resources are described by\n",
      " |      the `prediction_resources` field of the objects returned by\n",
      " |      `Endpoint.list_models()`. Because not all Models support all resource\n",
      " |      configuration types, the configuration types this Model supports are\n",
      " |      listed here.\n",
      " |\n",
      " |      If no configuration types are listed, the Model cannot be\n",
      " |      deployed to an `Endpoint` and does not support online predictions\n",
      " |      (`Endpoint.predict()` or `Endpoint.explain()`). Such a Model can serve\n",
      " |      predictions by using a `BatchPredictionJob`, if it has at least one entry\n",
      " |      each in `Model.supported_input_storage_formats` and\n",
      " |      `Model.supported_output_storage_formats`.\n",
      " |\n",
      " |  supported_export_formats\n",
      " |      The formats and content types in which this Model may be exported.\n",
      " |      If empty, this Model is not available for export.\n",
      " |\n",
      " |      For example, if this model can be exported as a Tensorflow SavedModel and\n",
      " |      have the artifacts written to Cloud Storage, the expected value would be:\n",
      " |\n",
      " |          {'tf-saved-model': [<ExportableContent.ARTIFACT: 1>]}\n",
      " |\n",
      " |  supported_input_storage_formats\n",
      " |      The formats this Model supports in the `input_config` field of a\n",
      " |      `BatchPredictionJob`. If `Model.predict_schemata.instance_schema_uri`\n",
      " |      exists, the instances should be given as per that schema.\n",
      " |\n",
      " |      [Read the docs for more on batch prediction formats](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions#batch_request_input)\n",
      " |\n",
      " |      If this Model doesn't support any of these formats it means it cannot be\n",
      " |      used with a `BatchPredictionJob`. However, if it has\n",
      " |      `supported_deployment_resources_types`, it could serve online predictions\n",
      " |      by using `Endpoint.predict()` or `Endpoint.explain()`.\n",
      " |\n",
      " |  supported_output_storage_formats\n",
      " |      The formats this Model supports in the `output_config` field of a\n",
      " |      `BatchPredictionJob`.\n",
      " |\n",
      " |      If both `Model.predict_schemata.instance_schema_uri` and\n",
      " |      `Model.predict_schemata.prediction_schema_uri` exist, the predictions\n",
      " |      are returned together with their instances. In other words, the\n",
      " |      prediction has the original instance data first, followed by the actual\n",
      " |      prediction content (as per the schema).\n",
      " |\n",
      " |      [Read the docs for more on batch prediction formats](https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions)\n",
      " |\n",
      " |      If this Model doesn't support any of these formats it means it cannot be\n",
      " |      used with a `BatchPredictionJob`. However, if it has\n",
      " |      `supported_deployment_resources_types`, it could serve online predictions\n",
      " |      by using `Endpoint.predict()` or `Endpoint.explain()`.\n",
      " |\n",
      " |  training_job\n",
      " |      The TrainingJob that uploaded this Model, if any.\n",
      " |\n",
      " |      Raises:\n",
      " |          api_core.exceptions.NotFound: If the Model's training job resource\n",
      " |              cannot be found on the Vertex service.\n",
      " |\n",
      " |  uri\n",
      " |      Path to the directory containing the Model artifact and any of its\n",
      " |      supporting files. Not present for AutoML Models.\n",
      " |\n",
      " |  version_aliases\n",
      " |      User provided version aliases so that a model version can be referenced via\n",
      " |      alias (i.e. projects/{project}/locations/{location}/models/{model_id}@{version_alias}\n",
      " |      instead of auto-generated version id (i.e.\n",
      " |      projects/{project}/locations/{location}/models/{model_id}@{version_id}).\n",
      " |      The format is [a-z][a-zA-Z0-9-]{0,126}[a-z0-9] to distinguish from\n",
      " |      version_id. A default version alias will be created for the first version\n",
      " |      of the model, and there must be exactly one default version alias for a model.\n",
      " |\n",
      " |  version_create_time\n",
      " |      Timestamp when this version was created.\n",
      " |\n",
      " |  version_description\n",
      " |      The description of this version.\n",
      " |\n",
      " |  version_id\n",
      " |      The version ID of the model.\n",
      " |      A new version is committed when a new model version is uploaded or\n",
      " |      trained under an existing model id. It is an auto-incrementing decimal\n",
      " |      number in string representation.\n",
      " |\n",
      " |  version_update_time\n",
      " |      Timestamp when this version was updated.\n",
      " |\n",
      " |  versioned_resource_name\n",
      " |      The fully-qualified resource name, including the version ID. For example,\n",
      " |      projects/{project}/locations/{location}/models/{model_id}@{version_id}\n",
      " |\n",
      " |  versioning_registry\n",
      " |      The registry of model versions associated with this\n",
      " |      Model instance.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  __annotations__ = {}\n",
      " |\n",
      " |  client_class = <class 'google.cloud.aiplatform.utils.ModelClientWithOv...\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from google.cloud.aiplatform.base.VertexAiResourceNounWithFutureManager:\n",
      " |\n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  delete(self, sync: bool = True) -> None\n",
      " |      Deletes this Vertex AI resource. WARNING: This deletion is\n",
      " |      permanent.\n",
      " |\n",
      " |      Args:\n",
      " |          sync (bool):\n",
      " |              Whether to execute this deletion synchronously. If False, this method\n",
      " |              will be executed in concurrent Future and any downstream object will\n",
      " |              be immediately returned and synced when the Future has completed.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from google.cloud.aiplatform.base.VertexAiResourceNoun:\n",
      " |\n",
      " |  to_dict(self) -> Dict[str, Any]\n",
      " |      Returns the resource proto as a dictionary.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from google.cloud.aiplatform.base.VertexAiResourceNoun:\n",
      " |\n",
      " |  create_time\n",
      " |      Time this resource was created.\n",
      " |\n",
      " |  display_name\n",
      " |      Display name of this resource.\n",
      " |\n",
      " |  encryption_spec\n",
      " |      Customer-managed encryption key options for this Vertex AI resource.\n",
      " |\n",
      " |      If this is set, then all resources created by this Vertex AI resource will\n",
      " |      be encrypted with the provided encryption key.\n",
      " |\n",
      " |  gca_resource\n",
      " |      The underlying resource proto representation.\n",
      " |\n",
      " |  labels\n",
      " |      User-defined labels containing metadata about this resource.\n",
      " |\n",
      " |      Read more about labels at https://goo.gl/xmQnxf\n",
      " |\n",
      " |  update_time\n",
      " |      Time this resource was last updated.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from google.cloud.aiplatform.base.VertexAiResourceNoun:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from google.cloud.aiplatform.base.FutureManager:\n",
      " |\n",
      " |  wait(self)\n",
      " |      Helper method that blocks until all futures are complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(aiplatform.Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9dacea-d1ed-43ee-a68c-ec213d982486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "da611172-1c42-4cd2-b7c7-a3ce7db82e2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Part.from_uri() missing 1 required positional argument: 'mime_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#tuned_model = TextGenerationModel.from_pretrained(tuned_model_name)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m uri \u001b[38;5;129;01min\u001b[39;00m subset:\n\u001b[0;32m----> 6\u001b[0m     image_part \u001b[38;5;241m=\u001b[39m Part\u001b[38;5;241m.\u001b[39mfrom_uri(uri)\n\u001b[1;32m      7\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount and identify the shapes in this image.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m     response \u001b[38;5;241m=\u001b[39m tuned_model\u001b[38;5;241m.\u001b[39mbatch_predict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgs://llm_shapes/export-data-train_20-2025-08-11T12:04:04.429366Z/image_bounding_box/train_20_image_bounding_box_2025_08_11_044322-5147888152479793152/data-00001-of-00001.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Part.from_uri() missing 1 required positional argument: 'mime_type'"
     ]
    }
   ],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel, InputOutputTextPair#, Part\n",
    "\n",
    "#tuned_model = TextGenerationModel.from_pretrained(tuned_model_name)\n",
    "\n",
    "for uri in subset:\n",
    "    image_part = Part.from_uri(uri)\n",
    "    prompt = \"Count and identify the shapes in this image.\"\n",
    "    \n",
    "    response = tuned_model.batch_predict(\"gs://llm_shapes/export-data-train_20-2025-08-11T12:04:04.429366Z/image_bounding_box/train_20_image_bounding_box_2025_08_11_044322-5147888152479793152/data-00001-of-00001.jsonl\")\n",
    "    \n",
    "    print(uri, \"->\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ae3a5a8b-9a86-4309-b173-70e177fff2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8cc66f52-9c83-499c-b926-007d11bd5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_image_paths(\"train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0bbde1ca-e34e-4876-8226-29e086535ad3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Part.from_uri() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 49\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content_stream(\n\u001b[1;32m     41\u001b[0m         model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m     42\u001b[0m         contents \u001b[38;5;241m=\u001b[39m contents,\n\u001b[1;32m     43\u001b[0m         config \u001b[38;5;241m=\u001b[39m generate_content_config,\n\u001b[1;32m     44\u001b[0m         ):\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28mprint\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mtext, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m generate(test)\n",
      "Cell \u001b[0;32mIn[120], line 15\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_uri \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m      9\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojects/665016930796/locations/us-central1/endpoints/3315004468000456704\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m     contents \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m       types\u001b[38;5;241m.\u001b[39mContent(\n\u001b[1;32m     12\u001b[0m         role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m         parts\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     14\u001b[0m             types\u001b[38;5;241m.\u001b[39mPart(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount and identify the shapes in this image.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m---> 15\u001b[0m             types\u001b[38;5;241m.\u001b[39mPart\u001b[38;5;241m.\u001b[39mfrom_uri(image_uri)\n\u001b[1;32m     16\u001b[0m   \n\u001b[1;32m     17\u001b[0m         ]\n\u001b[1;32m     18\u001b[0m       )\n\u001b[1;32m     19\u001b[0m     ]\n\u001b[1;32m     21\u001b[0m     generate_content_config \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mGenerateContentConfig(\n\u001b[1;32m     22\u001b[0m       temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     23\u001b[0m       top_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.95\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m       )],\n\u001b[1;32m     38\u001b[0m     )\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content_stream(\n\u001b[1;32m     41\u001b[0m       model \u001b[38;5;241m=\u001b[39m model,\n\u001b[1;32m     42\u001b[0m       contents \u001b[38;5;241m=\u001b[39m contents,\n\u001b[1;32m     43\u001b[0m       config \u001b[38;5;241m=\u001b[39m generate_content_config,\n\u001b[1;32m     44\u001b[0m       ):\n",
      "\u001b[0;31mTypeError\u001b[0m: Part.from_uri() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "def generate(dataset):\n",
    "  client = genai.Client(\n",
    "      vertexai=True,\n",
    "      project=\"665016930796\",\n",
    "      location=\"us-central1\",\n",
    "  )\n",
    "\n",
    "  for image_uri in dataset:\n",
    "      model = \"projects/665016930796/locations/us-central1/endpoints/3315004468000456704\"\n",
    "      contents = [\n",
    "        types.Content(\n",
    "          role=\"user\",\n",
    "          parts=[\n",
    "              types.Part(text=\"Count and identify the shapes in this image.\"),\n",
    "              types.Part.from_uri(image_uri)\n",
    "    \n",
    "          ]\n",
    "        )\n",
    "      ]\n",
    "    \n",
    "      generate_content_config = types.GenerateContentConfig(\n",
    "        temperature = 1,\n",
    "        top_p = 0.95,\n",
    "        max_output_tokens = 8192,\n",
    "        safety_settings = [types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "          threshold=\"OFF\"\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "          threshold=\"OFF\"\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "          threshold=\"OFF\"\n",
    "        ),types.SafetySetting(\n",
    "          category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "          threshold=\"OFF\"\n",
    "        )],\n",
    "      )\n",
    "    \n",
    "      for chunk in client.models.generate_content_stream(\n",
    "        model = model,\n",
    "        contents = contents,\n",
    "        config = generate_content_config,\n",
    "        ):\n",
    "        print(chunk.text, end=\"\")\n",
    "\n",
    " \n",
    "\n",
    "generate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ad93dc87-8243-4420-835b-393b8d501345",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Part.from_uri() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 37\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content_stream(\n\u001b[1;32m     29\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     30\u001b[0m             contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m     31\u001b[0m             config\u001b[38;5;241m=\u001b[39mgenerate_content_config,\n\u001b[1;32m     32\u001b[0m         ):\n\u001b[1;32m     33\u001b[0m             \u001b[38;5;28mprint\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mtext, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m generate(test)\n",
      "Cell \u001b[0;32mIn[112], line 15\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_uri \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m      9\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojects/665016930796/locations/us-central1/endpoints/3315004468000456704\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m     contents \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m         types\u001b[38;5;241m.\u001b[39mContent(\n\u001b[1;32m     12\u001b[0m             role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m             parts\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     14\u001b[0m                 types\u001b[38;5;241m.\u001b[39mPart(text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount and identify the shapes in this image.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m---> 15\u001b[0m                 types\u001b[38;5;241m.\u001b[39mPart\u001b[38;5;241m.\u001b[39mfrom_uri([image_uri, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage/png\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     16\u001b[0m             ]\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m     ]\n\u001b[1;32m     20\u001b[0m     generate_content_config \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mGenerateContentConfig(\n\u001b[1;32m     21\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     22\u001b[0m         top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m         stop_sequences\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEND\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mgenerate_content_stream(\n\u001b[1;32m     29\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     30\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m     31\u001b[0m         config\u001b[38;5;241m=\u001b[39mgenerate_content_config,\n\u001b[1;32m     32\u001b[0m     ):\n",
      "\u001b[0;31mTypeError\u001b[0m: Part.from_uri() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "def generate(dataset):\n",
    "#  client = genai.Client(\n",
    "#      vertexai=True,\n",
    "#      project=\"665016930796\",\n",
    "#      location=\"us-central1\",\n",
    "#  )\n",
    "\n",
    "    for image_uri in dataset:\n",
    "        model = \"projects/665016930796/locations/us-central1/endpoints/3315004468000456704\"\n",
    "        contents = [\n",
    "            types.Content(\n",
    "                role=\"user\",\n",
    "                parts=[\n",
    "                    types.Part(text=\"Count and identify the shapes in this image.\"),\n",
    "                    types.Part.from_uri([image_uri, \"image/png\"])\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "        generate_content_config = types.GenerateContentConfig(\n",
    "            temperature=1,\n",
    "            top_p=0.95,\n",
    "            candidate_count=1,\n",
    "            max_output_tokens=1024,\n",
    "            stop_sequences=[\"END\"]\n",
    "        )\n",
    "    \n",
    "        for chunk in client.models.generate_content_stream(\n",
    "            model=model,\n",
    "            contents=contents,\n",
    "            config=generate_content_config,\n",
    "        ):\n",
    "            print(chunk.text, end=\"\")\n",
    "\n",
    " \n",
    "\n",
    "generate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eabad6-0648-4165-bd83-187094b7a324",
   "metadata": {},
   "source": [
    "    Won't work, for some reason??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8c5a31be-6ede-49ed-a280-9e9e980279a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6a2fed51-3dfb-4245-bfc6-4c8219031f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.read_csv(\"responses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "68f8570b-9185-4444-b31d-a39004bc288e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pic_id</th>\n",
       "      <th>response</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gs://llm_shapes/r0_c8_t0_4.png</td>\n",
       "      <td>There are 8 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gs://llm_shapes/r0_c1_t0_3.png</td>\n",
       "      <td>There is 1 circle in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>gs://llm_shapes/r0_c2_t0_1.png</td>\n",
       "      <td>There are 2 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>gs://llm_shapes/r0_c7_t0.png</td>\n",
       "      <td>There are 6 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>gs://llm_shapes/r0_c2_t0_2.png</td>\n",
       "      <td>There are 2 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>gs://llm_shapes/r0_c4_t0_1.png</td>\n",
       "      <td>There are 4 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_4.png</td>\n",
       "      <td>There are 7 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>gs://llm_shapes/r0_c1_t0_5.png</td>\n",
       "      <td>There is 1 circle in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_1.png</td>\n",
       "      <td>There are 7 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>gs://llm_shapes/r0_c5_t0.png</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>gs://llm_shapes/r0_c1_t0_4.png</td>\n",
       "      <td>There is 1 circle in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>gs://llm_shapes/r0_c6_t0_2.png</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_5.png</td>\n",
       "      <td>There are 6 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>gs://llm_shapes/r0_c4_t0_5.png</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>gs://llm_shapes/r0_c6_t0_3.png</td>\n",
       "      <td>There are 6 circles in the image.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>gs://llm_shapes/r0_c5_t0.png</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_2.png</td>\n",
       "      <td>There are 7 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>gs://llm_shapes/r0_c6_t0_2.png</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_4.png</td>\n",
       "      <td>There are 7 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_4.png</td>\n",
       "      <td>There are 7 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>gs://llm_shapes/r0_c1_t0_1.png</td>\n",
       "      <td>There is 1 circle in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>gs://llm_shapes/r0_c3_t0.png</td>\n",
       "      <td>There are 3 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>gs://llm_shapes/r0_c1_t0.png</td>\n",
       "      <td>There is 1 circle in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>gs://llm_shapes/r0_c6_t0_1.png</td>\n",
       "      <td>There are 6 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>gs://llm_shapes/r0_c5_t0_1.png</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>gs://llm_shapes/r0_c0_t0_3.png</td>\n",
       "      <td>There are no circles in this image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>gs://llm_shapes/r0_c4_t0_4.png</td>\n",
       "      <td>There are 4 circles in the image.</td>\n",
       "      <td>Differently sized circles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>gs://llm_shapes/r0_c0_t5.png</td>\n",
       "      <td>There are no circles in the image.</td>\n",
       "      <td>Triangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>gs://llm_shapes/r0_c0_t7.png</td>\n",
       "      <td>There are no circles in the image.</td>\n",
       "      <td>Triangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>gs://llm_shapes/r0_c0_t3_2.png</td>\n",
       "      <td>There are no circles in the image.</td>\n",
       "      <td>Triangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>gs://llm_shapes/r0_c0_t3_1.png</td>\n",
       "      <td>There are no circles in the image.</td>\n",
       "      <td>Triangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>gs://llm_shapes/r0_c0_t0.png</td>\n",
       "      <td>There are no shapes in this image.</td>\n",
       "      <td>Triangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>gs://llm_shapes/r0_c0_t5.png</td>\n",
       "      <td>There are 5 shapes in the image, and they are ...</td>\n",
       "      <td>Triangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>gs://llm_shapes/r0_c0_t1_3.png</td>\n",
       "      <td>There is 1 shape in the image. It is a triangle.</td>\n",
       "      <td>Triangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>gs://llm_shapes/r0_c0_t3_1.png</td>\n",
       "      <td>There are 5 shapes in the image. They appear t...</td>\n",
       "      <td>Triangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>gs://llm_shapes/r0_c0_t1_2.png</td>\n",
       "      <td>There is 1 shape in the image. It is a triangle.</td>\n",
       "      <td>Triangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>gs://llm_shapes/d_r6_c0_t0_2.png</td>\n",
       "      <td>There are 7 shapes in the image.</td>\n",
       "      <td>Rectangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>gs://llm_shapes/d_r2_c0_t0.png</td>\n",
       "      <td>There are two shapes in the image.</td>\n",
       "      <td>Rectangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>gs://llm_shapes/s_r10_c0_t0_5.png</td>\n",
       "      <td>There are 9 shapes in the image.</td>\n",
       "      <td>Rectangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>gs://llm_shapes/s_r4_c0_t0.png</td>\n",
       "      <td>There are 4 shapes in the image.</td>\n",
       "      <td>Rectangles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>gs://llm_shapes/r7_c3_t0.png</td>\n",
       "      <td>Here's the shape count and identification for ...</td>\n",
       "      <td>Variety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>gs://llm_shapes/r1_c4_t1.png</td>\n",
       "      <td>Here's the breakdown of the shapes in the imag...</td>\n",
       "      <td>Variety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>gs://llm_shapes/r5_c1_t4.png</td>\n",
       "      <td>Here's the breakdown of shapes in the image:\\n...</td>\n",
       "      <td>Variety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>gs://llm_shapes/r3_c2_t3.png</td>\n",
       "      <td>Here's the shape count and identification:\\n\\n...</td>\n",
       "      <td>Variety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>gs://llm_shapes/r2_c2_t3.png</td>\n",
       "      <td>Here's a count and identification of the shape...</td>\n",
       "      <td>Variety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                             pic_id  \\\n",
       "0            0     gs://llm_shapes/r0_c8_t0_4.png   \n",
       "1            1     gs://llm_shapes/r0_c1_t0_3.png   \n",
       "2            2     gs://llm_shapes/r0_c2_t0_1.png   \n",
       "3            3       gs://llm_shapes/r0_c7_t0.png   \n",
       "4            4     gs://llm_shapes/r0_c2_t0_2.png   \n",
       "5            5     gs://llm_shapes/r0_c4_t0_1.png   \n",
       "6            6     gs://llm_shapes/r0_c7_t0_4.png   \n",
       "7            7     gs://llm_shapes/r0_c1_t0_5.png   \n",
       "8            8     gs://llm_shapes/r0_c7_t0_1.png   \n",
       "9            9       gs://llm_shapes/r0_c5_t0.png   \n",
       "10          10     gs://llm_shapes/r0_c1_t0_4.png   \n",
       "11          11     gs://llm_shapes/r0_c6_t0_2.png   \n",
       "12          12     gs://llm_shapes/r0_c7_t0_5.png   \n",
       "13          13     gs://llm_shapes/r0_c4_t0_5.png   \n",
       "14          14     gs://llm_shapes/r0_c6_t0_3.png   \n",
       "15          15       gs://llm_shapes/r0_c5_t0.png   \n",
       "16          16     gs://llm_shapes/r0_c7_t0_2.png   \n",
       "17          17     gs://llm_shapes/r0_c6_t0_2.png   \n",
       "18          18     gs://llm_shapes/r0_c7_t0_4.png   \n",
       "19          19     gs://llm_shapes/r0_c7_t0_4.png   \n",
       "20          20     gs://llm_shapes/r0_c1_t0_1.png   \n",
       "21          21       gs://llm_shapes/r0_c3_t0.png   \n",
       "22          22       gs://llm_shapes/r0_c1_t0.png   \n",
       "23          23     gs://llm_shapes/r0_c6_t0_1.png   \n",
       "24          24     gs://llm_shapes/r0_c5_t0_1.png   \n",
       "25          25     gs://llm_shapes/r0_c0_t0_3.png   \n",
       "26          26     gs://llm_shapes/r0_c4_t0_4.png   \n",
       "27          27       gs://llm_shapes/r0_c0_t5.png   \n",
       "28          28       gs://llm_shapes/r0_c0_t7.png   \n",
       "29          29     gs://llm_shapes/r0_c0_t3_2.png   \n",
       "30          30     gs://llm_shapes/r0_c0_t3_1.png   \n",
       "31          31       gs://llm_shapes/r0_c0_t0.png   \n",
       "32          32       gs://llm_shapes/r0_c0_t5.png   \n",
       "33          33     gs://llm_shapes/r0_c0_t1_3.png   \n",
       "34          34     gs://llm_shapes/r0_c0_t3_1.png   \n",
       "35          35     gs://llm_shapes/r0_c0_t1_2.png   \n",
       "36          36   gs://llm_shapes/d_r6_c0_t0_2.png   \n",
       "37          37     gs://llm_shapes/d_r2_c0_t0.png   \n",
       "38          38  gs://llm_shapes/s_r10_c0_t0_5.png   \n",
       "39          39     gs://llm_shapes/s_r4_c0_t0.png   \n",
       "40          40       gs://llm_shapes/r7_c3_t0.png   \n",
       "41          41       gs://llm_shapes/r1_c4_t1.png   \n",
       "42          42       gs://llm_shapes/r5_c1_t4.png   \n",
       "43          43       gs://llm_shapes/r3_c2_t3.png   \n",
       "44          44       gs://llm_shapes/r2_c2_t3.png   \n",
       "\n",
       "                                             response  \\\n",
       "0                   There are 8 circles in the image.   \n",
       "1                     There is 1 circle in the image.   \n",
       "2                   There are 2 circles in the image.   \n",
       "3                   There are 6 circles in the image.   \n",
       "4                   There are 2 circles in the image.   \n",
       "5                   There are 4 circles in the image.   \n",
       "6                   There are 7 circles in the image.   \n",
       "7                     There is 1 circle in the image.   \n",
       "8                   There are 7 circles in the image.   \n",
       "9                   There are 5 circles in the image.   \n",
       "10                    There is 1 circle in the image.   \n",
       "11                  There are 5 circles in the image.   \n",
       "12                  There are 6 circles in the image.   \n",
       "13                  There are 5 circles in the image.   \n",
       "14                  There are 6 circles in the image.   \n",
       "15                  There are 5 circles in the image.   \n",
       "16                  There are 7 circles in the image.   \n",
       "17                  There are 5 circles in the image.   \n",
       "18                  There are 7 circles in the image.   \n",
       "19                  There are 7 circles in the image.   \n",
       "20                    There is 1 circle in the image.   \n",
       "21                  There are 3 circles in the image.   \n",
       "22                    There is 1 circle in the image.   \n",
       "23                  There are 6 circles in the image.   \n",
       "24                  There are 5 circles in the image.   \n",
       "25                There are no circles in this image.   \n",
       "26                  There are 4 circles in the image.   \n",
       "27                 There are no circles in the image.   \n",
       "28                 There are no circles in the image.   \n",
       "29                 There are no circles in the image.   \n",
       "30                 There are no circles in the image.   \n",
       "31                 There are no shapes in this image.   \n",
       "32  There are 5 shapes in the image, and they are ...   \n",
       "33   There is 1 shape in the image. It is a triangle.   \n",
       "34  There are 5 shapes in the image. They appear t...   \n",
       "35   There is 1 shape in the image. It is a triangle.   \n",
       "36                   There are 7 shapes in the image.   \n",
       "37                 There are two shapes in the image.   \n",
       "38                   There are 9 shapes in the image.   \n",
       "39                   There are 4 shapes in the image.   \n",
       "40  Here's the shape count and identification for ...   \n",
       "41  Here's the breakdown of the shapes in the imag...   \n",
       "42  Here's the breakdown of shapes in the image:\\n...   \n",
       "43  Here's the shape count and identification:\\n\\n...   \n",
       "44  Here's a count and identification of the shape...   \n",
       "\n",
       "                        notes  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "5                         NaN  \n",
       "6                         NaN  \n",
       "7                         NaN  \n",
       "8                         NaN  \n",
       "9                         NaN  \n",
       "10                        NaN  \n",
       "11                        NaN  \n",
       "12                        NaN  \n",
       "13                        NaN  \n",
       "14                        NaN  \n",
       "15  Differently sized circles  \n",
       "16  Differently sized circles  \n",
       "17  Differently sized circles  \n",
       "18  Differently sized circles  \n",
       "19  Differently sized circles  \n",
       "20  Differently sized circles  \n",
       "21  Differently sized circles  \n",
       "22  Differently sized circles  \n",
       "23  Differently sized circles  \n",
       "24  Differently sized circles  \n",
       "25  Differently sized circles  \n",
       "26  Differently sized circles  \n",
       "27                  Triangles  \n",
       "28                  Triangles  \n",
       "29                  Triangles  \n",
       "30                  Triangles  \n",
       "31                  Triangles  \n",
       "32                  Triangles  \n",
       "33                  Triangles  \n",
       "34                  Triangles  \n",
       "35                  Triangles  \n",
       "36                 Rectangles  \n",
       "37                 Rectangles  \n",
       "38                 Rectangles  \n",
       "39                 Rectangles  \n",
       "40                    Variety  \n",
       "41                    Variety  \n",
       "42                    Variety  \n",
       "43                    Variety  \n",
       "44                    Variety  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0b1a5e46-a852-4550-8db3-ee9288e88df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circle count accuracy: 82.22%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pic_id</th>\n",
       "      <th>gt_circles</th>\n",
       "      <th>pred_circles</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://llm_shapes/r0_c7_t0.png</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>There are 6 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gs://llm_shapes/r0_c6_t0_2.png</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_5.png</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>There are 6 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gs://llm_shapes/r0_c4_t0_5.png</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gs://llm_shapes/r0_c6_t0_2.png</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>gs://llm_shapes/r7_c3_t0.png</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Here's the shape count and identification for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>gs://llm_shapes/r1_c4_t1.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Here's the breakdown of the shapes in the imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>gs://llm_shapes/r3_c2_t3.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Here's the shape count and identification:\\n\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            pic_id  gt_circles  pred_circles  \\\n",
       "3     gs://llm_shapes/r0_c7_t0.png           7             6   \n",
       "11  gs://llm_shapes/r0_c6_t0_2.png           6             5   \n",
       "12  gs://llm_shapes/r0_c7_t0_5.png           7             6   \n",
       "13  gs://llm_shapes/r0_c4_t0_5.png           4             5   \n",
       "17  gs://llm_shapes/r0_c6_t0_2.png           6             5   \n",
       "40    gs://llm_shapes/r7_c3_t0.png           3             0   \n",
       "41    gs://llm_shapes/r1_c4_t1.png           4             0   \n",
       "43    gs://llm_shapes/r3_c2_t3.png           2             0   \n",
       "\n",
       "                                             response  \n",
       "3                   There are 6 circles in the image.  \n",
       "11                  There are 5 circles in the image.  \n",
       "12                  There are 6 circles in the image.  \n",
       "13                  There are 5 circles in the image.  \n",
       "17                  There are 5 circles in the image.  \n",
       "40  Here's the shape count and identification for ...  \n",
       "41  Here's the breakdown of the shapes in the imag...  \n",
       "43  Here's the shape count and identification:\\n\\n...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Example: your dataframe\n",
    "df = responses.copy()\n",
    "\n",
    "# 1. Extract ground truth counts from filename\n",
    "def parse_ground_truth(filename):\n",
    "    match = re.search(r\"r(\\d+)_c(\\d+)_t(\\d+)\", filename)\n",
    "    if match:\n",
    "        rects, circles, triangles = map(int, match.groups())\n",
    "        return rects, circles, triangles\n",
    "    return None, None, None\n",
    "\n",
    "df[['gt_rects', 'gt_circles', 'gt_triangles']] = df['pic_id'].apply(\n",
    "    lambda x: pd.Series(parse_ground_truth(x))\n",
    ")\n",
    "\n",
    "# 2. Extract predicted counts from response\n",
    "def parse_prediction(text):\n",
    "    # Look for \"[number] circle(s)\" first\n",
    "    circle_match = re.search(r\"(\\d+)\\s+circle\", text)\n",
    "    if circle_match:\n",
    "        return int(circle_match.group(1))\n",
    "    return 0  # if it can't find one\n",
    "\n",
    "df['pred_circles'] = df['response'].apply(parse_prediction)\n",
    "\n",
    "# 3. Compare and grade\n",
    "df['circle_correct'] = df['pred_circles'] == df['gt_circles']\n",
    "\n",
    "# 4. Simple accuracy score\n",
    "accuracy = df['circle_correct'].mean()\n",
    "print(f\"Circle count accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# 5. View mismatches\n",
    "mismatches = df[df['circle_correct'] == False]\n",
    "mismatches[['pic_id', 'gt_circles', 'pred_circles', 'response']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "864b36b7-ec84-48a4-938a-c233e2e3b65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectangle accuracy: 82.22%\n",
      "Circle accuracy: 82.22%\n",
      "Triangle accuracy: 75.56%\n",
      "Average accuracy: 80.00%\n",
      "\n",
      "Mismatches:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pic_id</th>\n",
       "      <th>gt_rects</th>\n",
       "      <th>pred_rects</th>\n",
       "      <th>gt_circles</th>\n",
       "      <th>pred_circles</th>\n",
       "      <th>gt_triangles</th>\n",
       "      <th>pred_triangles</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://llm_shapes/r0_c7_t0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are 6 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gs://llm_shapes/r0_c6_t0_2.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gs://llm_shapes/r0_c7_t0_5.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are 6 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gs://llm_shapes/r0_c4_t0_5.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gs://llm_shapes/r0_c6_t0_2.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are 5 circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gs://llm_shapes/r0_c0_t5.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>There are no circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>gs://llm_shapes/r0_c0_t7.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>There are no circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gs://llm_shapes/r0_c0_t3_2.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>There are no circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>gs://llm_shapes/r0_c0_t3_1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>There are no circles in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gs://llm_shapes/r0_c0_t5.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>There are 5 shapes in the image, and they are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gs://llm_shapes/r0_c0_t1_3.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>There is 1 shape in the image. It is a triangle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gs://llm_shapes/r0_c0_t3_1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>There are 5 shapes in the image. They appear t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>gs://llm_shapes/r0_c0_t1_2.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>There is 1 shape in the image. It is a triangle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>gs://llm_shapes/d_r6_c0_t0_2.png</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are 7 shapes in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gs://llm_shapes/d_r2_c0_t0.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are two shapes in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>gs://llm_shapes/s_r10_c0_t0_5.png</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are 9 shapes in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>gs://llm_shapes/s_r4_c0_t0.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are 4 shapes in the image.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>gs://llm_shapes/r7_c3_t0.png</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Here's the shape count and identification for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>gs://llm_shapes/r1_c4_t1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Here's the breakdown of the shapes in the imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>gs://llm_shapes/r5_c1_t4.png</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Here's the breakdown of shapes in the image:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>gs://llm_shapes/r3_c2_t3.png</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Here's the shape count and identification:\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>gs://llm_shapes/r2_c2_t3.png</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Here's a count and identification of the shape...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               pic_id  gt_rects  pred_rects  gt_circles  \\\n",
       "3        gs://llm_shapes/r0_c7_t0.png         0           0           7   \n",
       "11     gs://llm_shapes/r0_c6_t0_2.png         0           0           6   \n",
       "12     gs://llm_shapes/r0_c7_t0_5.png         0           0           7   \n",
       "13     gs://llm_shapes/r0_c4_t0_5.png         0           0           4   \n",
       "17     gs://llm_shapes/r0_c6_t0_2.png         0           0           6   \n",
       "27       gs://llm_shapes/r0_c0_t5.png         0           0           0   \n",
       "28       gs://llm_shapes/r0_c0_t7.png         0           0           0   \n",
       "29     gs://llm_shapes/r0_c0_t3_2.png         0           0           0   \n",
       "30     gs://llm_shapes/r0_c0_t3_1.png         0           0           0   \n",
       "32       gs://llm_shapes/r0_c0_t5.png         0           0           0   \n",
       "33     gs://llm_shapes/r0_c0_t1_3.png         0           0           0   \n",
       "34     gs://llm_shapes/r0_c0_t3_1.png         0           0           0   \n",
       "35     gs://llm_shapes/r0_c0_t1_2.png         0           0           0   \n",
       "36   gs://llm_shapes/d_r6_c0_t0_2.png         6           0           0   \n",
       "37     gs://llm_shapes/d_r2_c0_t0.png         2           0           0   \n",
       "38  gs://llm_shapes/s_r10_c0_t0_5.png        10           0           0   \n",
       "39     gs://llm_shapes/s_r4_c0_t0.png         4           0           0   \n",
       "40       gs://llm_shapes/r7_c3_t0.png         7           0           3   \n",
       "41       gs://llm_shapes/r1_c4_t1.png         1           0           4   \n",
       "42       gs://llm_shapes/r5_c1_t4.png         5           5           1   \n",
       "43       gs://llm_shapes/r3_c2_t3.png         3           0           2   \n",
       "44       gs://llm_shapes/r2_c2_t3.png         2           1           2   \n",
       "\n",
       "    pred_circles  gt_triangles  pred_triangles  \\\n",
       "3              6             0               0   \n",
       "11             5             0               0   \n",
       "12             6             0               0   \n",
       "13             5             0               0   \n",
       "17             5             0               0   \n",
       "27             0             5               0   \n",
       "28             0             7               0   \n",
       "29             0             3               0   \n",
       "30             0             3               0   \n",
       "32             0             5               0   \n",
       "33             0             1               0   \n",
       "34             0             3               0   \n",
       "35             0             1               0   \n",
       "36             0             0               0   \n",
       "37             0             0               0   \n",
       "38             0             0               0   \n",
       "39             0             0               0   \n",
       "40             0             0               0   \n",
       "41             0             1               0   \n",
       "42             1             4               3   \n",
       "43             0             3               0   \n",
       "44             2             3               3   \n",
       "\n",
       "                                             response  \n",
       "3                   There are 6 circles in the image.  \n",
       "11                  There are 5 circles in the image.  \n",
       "12                  There are 6 circles in the image.  \n",
       "13                  There are 5 circles in the image.  \n",
       "17                  There are 5 circles in the image.  \n",
       "27                 There are no circles in the image.  \n",
       "28                 There are no circles in the image.  \n",
       "29                 There are no circles in the image.  \n",
       "30                 There are no circles in the image.  \n",
       "32  There are 5 shapes in the image, and they are ...  \n",
       "33   There is 1 shape in the image. It is a triangle.  \n",
       "34  There are 5 shapes in the image. They appear t...  \n",
       "35   There is 1 shape in the image. It is a triangle.  \n",
       "36                   There are 7 shapes in the image.  \n",
       "37                 There are two shapes in the image.  \n",
       "38                   There are 9 shapes in the image.  \n",
       "39                   There are 4 shapes in the image.  \n",
       "40  Here's the shape count and identification for ...  \n",
       "41  Here's the breakdown of the shapes in the imag...  \n",
       "42  Here's the breakdown of shapes in the image:\\n...  \n",
       "43  Here's the shape count and identification:\\n\\n...  \n",
       "44  Here's a count and identification of the shape...  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_ground_truth(filename):\n",
    "    match = re.search(r\"r(\\d+)_c(\\d+)_t(\\d+)\", filename)\n",
    "    if match:\n",
    "        rects, circles, triangles = map(int, match.groups())\n",
    "        return rects, circles, triangles\n",
    "    return None, None, None\n",
    "\n",
    "df[['gt_rects', 'gt_circles', 'gt_triangles']] = df['pic_id'].apply(\n",
    "    lambda x: pd.Series(parse_ground_truth(x))\n",
    ")\n",
    "\n",
    "# 2. Parse predicted counts for each shape\n",
    "def parse_shape_count(text, keywords):\n",
    "    \"\"\"\n",
    "    Look for a number before any of the keywords in the string.\n",
    "    keywords: list of possible shape names\n",
    "    \"\"\"\n",
    "    pattern = r\"(\\d+)\\s+(?:\" + \"|\".join(keywords) + r\")\\b\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return 0  # assume 0 if not mentioned\n",
    "\n",
    "df['pred_rects'] = df['response'].apply(lambda t: parse_shape_count(t, [\"rectangle\", \"rectangles\", \"square\", \"squares\"]))\n",
    "df['pred_circles'] = df['response'].apply(lambda t: parse_shape_count(t, [\"circle\", \"circles\"]))\n",
    "df['pred_triangles'] = df['response'].apply(lambda t: parse_shape_count(t, [\"triangle\", \"triangles\"]))\n",
    "\n",
    "# 3. Compare predictions to ground truth\n",
    "df['rect_correct'] = df['pred_rects'] == df['gt_rects']\n",
    "df['circle_correct'] = df['pred_circles'] == df['gt_circles']\n",
    "df['triangle_correct'] = df['pred_triangles'] == df['gt_triangles']\n",
    "\n",
    "# 4. Overall accuracy per shape\n",
    "acc_rect = df['rect_correct'].mean()\n",
    "acc_circle = df['circle_correct'].mean()\n",
    "acc_triangle = df['triangle_correct'].mean()\n",
    "\n",
    "print(f\"Rectangle accuracy: {acc_rect:.2%}\")\n",
    "print(f\"Circle accuracy: {acc_circle:.2%}\")\n",
    "print(f\"Triangle accuracy: {acc_triangle:.2%}\")\n",
    "print(f\"Average accuracy: {((acc_triangle+acc_rect+acc_circle)/3):.2%}\")\n",
    "\n",
    "# 5. View errors\n",
    "mismatches = df[(~df['rect_correct']) | (~df['circle_correct']) | (~df['triangle_correct'])]\n",
    "print(\"\\nMismatches:\")\n",
    "mismatches[['pic_id', 'gt_rects', 'pred_rects', 'gt_circles', 'pred_circles', 'gt_triangles', 'pred_triangles', 'response']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f4964182-4e0e-4b83-b4e8-7f61bb0a0c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shape</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rectangle</td>\n",
       "      <td>0.8222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Triangle</td>\n",
       "      <td>0.7556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Circle</td>\n",
       "      <td>0.8222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Average</td>\n",
       "      <td>0.8000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Shape  Accuracy\n",
       "0  Rectangle    0.8222\n",
       "1   Triangle    0.7556\n",
       "2     Circle    0.8222\n",
       "3    Average    0.8000"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([{\"Shape\":\"Rectangle\",\"Accuracy\":0.8222},\n",
    "             {\"Shape\":\"Triangle\",\"Accuracy\":0.7556},\n",
    "             {\"Shape\":\"Circle\",\"Accuracy\":0.8222},\n",
    "             {\"Shape\":\"Average\",\"Accuracy\":0.8},\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeaaf36-9b34-4d6e-a350-0949e50a7020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
